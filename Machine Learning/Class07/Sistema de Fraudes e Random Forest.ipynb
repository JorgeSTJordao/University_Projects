{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2154826d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea65d9f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X=np.load(\"Cred_features.npy\")\n",
    "y=np.load(\"Cred_labels.npy\")\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e66f3dad",
   "metadata": {},
   "source": [
    "### K-nearest neighbors algorithm\n",
    "\n",
    "- <b>Parâmetros KNN</b> \n",
    "    - N_neighbors: nº de vizinhos considerados próximos da amostra \n",
    "    - Weights: uniform ( All points in each neighborhood are weighted equally) \n",
    "    - Weights: distance (in this case, closer neighbors of a query point will have a greater influence than neighbors which are further away)\n",
    "    - p: [1,2] (When p = 1, this is equivalent to using manhattan_distance (l1), and euclidean_distance (l2) for p = 2)\n",
    "---\n",
    "- <b>Validação</b>: ele fará de maneira sistemática diversas combinações dos parâmetros e depois de avaliá-los os armazenará num único objeto. Nesse sentido, será feito uma análise combinatória a partir da quantidade de elementos em cada matriz com outros\n",
    "    - Arrays: X, y (Allowed inputs are lists, numpy arrays, scipy-sparse matrices or pandas dataframes)\n",
    "    - test_size + train_size = 1.0 (should be between 0.0 and 1.0 and represent the proportion of the dataset to include in the test split)\n",
    "    - Random_state: 42 (Pass an int for reproducible output across multiple function calls)\n",
    "    - Stratify: y (Data is split in a stratified fashion, using this as the class labels)  \n",
    "---\n",
    "- <b>GridSearchCV</b>\n",
    "    - Estimator: clf (o classificador ou regressor que estamos utilizando)\n",
    "    - Param_grid: parameters (é aquele dicionário com valores para serem testados)\n",
    "    - scoring: 'accuracy' ()\n",
    "    - cv: 5 (cv é um número inteiro o GridSearchCV executa um StratifiedKFolds, isso quer dizer que o dataset foi divido em 5 partes (ou folds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ace7fe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "parameters=[{'n_neighbors':[1,3,5,7,9,11], 'weights': ['uniform', 'distance'], 'p':[1,2]}]\n",
    "\n",
    "# Separando uma parte dos dados para validação (usaremos no GridSearchCV)\n",
    "X,X_val,y,y_val=train_test_split(X,y,test_size=0.2,random_state=42, stratify=y)\n",
    "\n",
    "clf = KNeighborsClassifier()\n",
    "\n",
    "# Execução do GridSearch\n",
    "gs=GridSearchCV(clf, parameters, scoring='accuracy', cv=5, n_jobs=-1)\n",
    "\n",
    "gs.fit(X_val, y_val)\n",
    "# Mostrando a tabela de resultados do GridSearch (opcional)\n",
    "#from tabulate import tabulate\n",
    "import pandas as pd\n",
    "df=gs.cv_results_\n",
    "df = pd.DataFrame(gs.cv_results_)\n",
    "#print(tabulate(df, headers='keys', tablefmt='psql'))\n",
    "#print(\"Melhores parâmetros encontrados: \", gs.best_params_)\n",
    "\n",
    "# Recuperando os melhores resultados\n",
    "#clf=gs.best_estimator_\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed4348a8",
   "metadata": {},
   "source": [
    "### Naive Bayes classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa24fcf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X=np.load(\"Cred_features.npy\")\n",
    "y=np.load(\"Cred_labels.npy\")\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "\n",
    "# Validação cruzada\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "# Separando da base original uma parte para validação\n",
    "X,x_val,y,y_val=train_test_split(X,y,test_size=0.2,random_state=42, stratify=y)\n",
    "\n",
    "# Declara o modelo\n",
    "clf=GaussianNB()\n",
    "\n",
    "# parâmetros que o GridSearch utilizará em sua busca (KNN)\n",
    "\n",
    "# parâmetros Naive Bayes\n",
    "parameters=[{'var_smoothing':[1e-09,1e-03, 1e-06]}]\n",
    "\n",
    "# Execução do GridSearch\n",
    "gs=GridSearchCV(clf, parameters, scoring='accuracy', cv=3, n_jobs=-1)\n",
    "gs.fit(x_val, y_val)\n",
    "\n",
    "# Mostrando a tabela de resultados do GrifSearch (opcional)\n",
    "#from tabulate import tabulate\n",
    "import pandas as pd\n",
    "df=gs.cv_results_\n",
    "df = pd.DataFrame(gs.cv_results_)\n",
    "#print(tabulate(df, headers='keys', tablefmt='psql'))\n",
    "print(\"Melhores parâmetros encontrados: \", gs.best_params_)\n",
    "\n",
    "# Recuperando os melhores resultados\n",
    "clf=gs.best_estimator_\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "830c83d4",
   "metadata": {},
   "source": [
    "### Decision Tree Algorithm\n",
    "\n",
    "- Parâmetros DecisionTree\n",
    "    - criterion: ['gini', 'entropy', 'log_loss'] (The function to measure the quality of a split.)\n",
    "    - max_depth: [None, 5, 10] (The maximum depth of the tree)\n",
    "    - min_samples_split:[2, 5] (The minimum number of samples required to split an internal node)\n",
    "    - splitter:['random', 'best'] (The strategy used to choose the split at each node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde1aa90",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=np.load(\"Cred_features.npy\")\n",
    "y=np.load(\"Cred_labels.npy\")\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "\n",
    "# Validação cruzada\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "# Separando da base original uma parte para validação\n",
    "X,x_val,y,y_val=train_test_split(X,y,test_size=0.2,random_state=42, stratify=y)\n",
    "\n",
    "# Declara o modelo\n",
    "clf=DecisionTreeClassifier()\n",
    "\n",
    "# parâmetros para árvore de classificação (DecisionTree)\n",
    "parameters=[{'criterion':['gini', 'entropy', 'log_loss'],\n",
    "             'max_depth': [None, 5, 10],\n",
    "             'min_samples_split':[2, 5],\n",
    "             'splitter':['random', 'best']}]\n",
    "\n",
    "\n",
    "# Execução do GridSearch\n",
    "gs=GridSearchCV(clf, parameters, scoring='accuracy', cv=3, n_jobs=-1)\n",
    "gs.fit(x_val, y_val)\n",
    "\n",
    "# Mostrando a tabela de resultados do GrifSearch (opcional)\n",
    "#from tabulate import tabulate\n",
    "import pandas as pd\n",
    "df=gs.cv_results_\n",
    "df = pd.DataFrame(gs.cv_results_)\n",
    "#print(tabulate(df, headers='keys', tablefmt='psql'))\n",
    "print(\"Melhores parâmetros encontrados: \", gs.best_params_)\n",
    "\n",
    "# Recuperando os melhores resultados\n",
    "clf=gs.best_estimator_\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f06b3a9",
   "metadata": {},
   "source": [
    "### Multilayer Perceptron (MLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ac4887",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=np.load(\"Cred_features.npy\")\n",
    "y=np.load(\"Cred_labels.npy\")\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "\n",
    "# Validação cruzada\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "# Separando da base original uma parte para validação\n",
    "X,x_val,y,y_val=train_test_split(X,y,test_size=0.2,random_state=42, stratify=y)\n",
    "\n",
    "# Declara o modelo\n",
    "clf=MLPClassifier(max_iter=300, early_stopping=False, solver='adam')\n",
    "\n",
    "# parâmetros para MLP (Rede Neural Artificial - MultiLayer Perceptron)\n",
    "parameters=[{'hidden_layer_sizes':[16, (16, 8), (16, 8, 4)],\n",
    "             'learning_rate': ['constant', 'invscaling'],\n",
    "             'learning_rate_init':[0.01, 0.001, 0.0001],\n",
    "             'activation':['relu', 'logistic', 'tanh'],\n",
    "             'random_state':[10, 46, 37]}]\n",
    "\n",
    "# Execução do GridSearch\n",
    "gs=GridSearchCV(clf, parameters, scoring='accuracy', cv=3, n_jobs=-1)\n",
    "gs.fit(x_val, y_val)\n",
    "\n",
    "# Mostrando a tabela de resultados do GrifSearch (opcional)\n",
    "#from tabulate import tabulate\n",
    "import pandas as pd\n",
    "#df=gs.cv_results_\n",
    "#df = pd.DataFrame(gs.cv_results_)\n",
    "#print(tabulate(df, headers='keys', tablefmt='psql'))\n",
    "print(\"Melhores parâmetros encontrados: \", gs.best_params_)\n",
    "\n",
    "# Recuperando os melhores resultados\n",
    "clf=gs.best_estimator_\n",
    "#df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55bcac74",
   "metadata": {},
   "source": [
    "### Metrics to Evaluate your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "696d1542",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Métricas de avaliação\n",
    "\n",
    "# Usando validação cruzada com T=5 folds\n",
    "result=model_selection.cross_val_score(clf, X, y, cv=5)\n",
    "print(\"Acurácia média: %.3f\" % result.mean())\n",
    "print(\"Desvio padrão: %.3f\" % result.std())\n",
    "\n",
    "# Calculando a predição para cada exempolo de teste\n",
    "y_pred=model_selection.cross_val_predict(clf, X, y, cv=5)\n",
    "\n",
    "# Calculando a predição para cada exemplo de teste\n",
    "#y_pred_proba=model_selection.cross_val_predict(clf, X, y, cv=5, method='predict_proba')\n",
    "\n",
    "# Calcular precisão\n",
    "precision=precision_score(y, y_pred, average='macro')\n",
    "\n",
    "# Calcular revocação\n",
    "recall=recall_score(y, y_pred, average='macro')\n",
    "\n",
    "# Calcular revocação\n",
    "f1=f1_score(y, y_pred, average='macro')\n",
    "\n",
    "print(\"Precision: %.3f\" % precision)\n",
    "print(\"Recall: %.3f\" % recall)\n",
    "print(\"f1: %.3f\" % f1)\n",
    "\n",
    "matrix=ConfusionMatrixDisplay(y, y_pred)\n",
    "cm = confusion_matrix(y, y_pred, labels=clf.classes_)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['benigno', 'maligno'])\n",
    "disp.plot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
