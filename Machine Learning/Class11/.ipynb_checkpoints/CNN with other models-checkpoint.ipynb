{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "300bfcdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Classifiers and Ensembles\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "# Metrics\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0352c21e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2040,)\n",
      "(2040, 2048)\n",
      "(2040,)\n"
     ]
    }
   ],
   "source": [
    "# Labels\n",
    "y = pd.read_csv('y_im.csv', header=None)\n",
    "y=y.to_numpy()\n",
    "y=np.ravel(y)\n",
    "print(y.shape)\n",
    "\n",
    "# deep features\n",
    "X = pd.read_csv('X_im.csv', header=None)\n",
    "X=X.to_numpy()\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2aabc060",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhores par√¢metros encontrados:  {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 2, 'splitter': 'random'}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_criterion</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_min_samples_split</th>\n",
       "      <th>param_splitter</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.102667</td>\n",
       "      <td>0.006733</td>\n",
       "      <td>0.001422</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>gini</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>random</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': None, 'min_...</td>\n",
       "      <td>0.548780</td>\n",
       "      <td>0.475610</td>\n",
       "      <td>0.463415</td>\n",
       "      <td>0.469136</td>\n",
       "      <td>0.493827</td>\n",
       "      <td>0.490154</td>\n",
       "      <td>0.031045</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.624601</td>\n",
       "      <td>0.068204</td>\n",
       "      <td>0.001910</td>\n",
       "      <td>0.001181</td>\n",
       "      <td>gini</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>best</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': None, 'min_...</td>\n",
       "      <td>0.341463</td>\n",
       "      <td>0.512195</td>\n",
       "      <td>0.475610</td>\n",
       "      <td>0.567901</td>\n",
       "      <td>0.481481</td>\n",
       "      <td>0.475730</td>\n",
       "      <td>0.074680</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.075625</td>\n",
       "      <td>0.007734</td>\n",
       "      <td>0.001738</td>\n",
       "      <td>0.000854</td>\n",
       "      <td>gini</td>\n",
       "      <td>None</td>\n",
       "      <td>5</td>\n",
       "      <td>random</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': None, 'min_...</td>\n",
       "      <td>0.463415</td>\n",
       "      <td>0.560976</td>\n",
       "      <td>0.439024</td>\n",
       "      <td>0.469136</td>\n",
       "      <td>0.530864</td>\n",
       "      <td>0.492683</td>\n",
       "      <td>0.045633</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.602447</td>\n",
       "      <td>0.059214</td>\n",
       "      <td>0.001295</td>\n",
       "      <td>0.000075</td>\n",
       "      <td>gini</td>\n",
       "      <td>None</td>\n",
       "      <td>5</td>\n",
       "      <td>best</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': None, 'min_...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.451220</td>\n",
       "      <td>0.463415</td>\n",
       "      <td>0.617284</td>\n",
       "      <td>0.419753</td>\n",
       "      <td>0.490334</td>\n",
       "      <td>0.068478</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.046888</td>\n",
       "      <td>0.013620</td>\n",
       "      <td>0.001339</td>\n",
       "      <td>0.000091</td>\n",
       "      <td>gini</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>random</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 5, 'min_sam...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.560976</td>\n",
       "      <td>0.548780</td>\n",
       "      <td>0.543210</td>\n",
       "      <td>0.419753</td>\n",
       "      <td>0.514544</td>\n",
       "      <td>0.051665</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.425438</td>\n",
       "      <td>0.008953</td>\n",
       "      <td>0.001300</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>gini</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>best</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 5, 'min_sam...</td>\n",
       "      <td>0.475610</td>\n",
       "      <td>0.402439</td>\n",
       "      <td>0.426829</td>\n",
       "      <td>0.580247</td>\n",
       "      <td>0.456790</td>\n",
       "      <td>0.468383</td>\n",
       "      <td>0.061279</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.039107</td>\n",
       "      <td>0.006686</td>\n",
       "      <td>0.001293</td>\n",
       "      <td>0.000070</td>\n",
       "      <td>gini</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>random</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 5, 'min_sam...</td>\n",
       "      <td>0.536585</td>\n",
       "      <td>0.463415</td>\n",
       "      <td>0.536585</td>\n",
       "      <td>0.518519</td>\n",
       "      <td>0.481481</td>\n",
       "      <td>0.507317</td>\n",
       "      <td>0.029778</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.415766</td>\n",
       "      <td>0.004519</td>\n",
       "      <td>0.001346</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>gini</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>best</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 5, 'min_sam...</td>\n",
       "      <td>0.463415</td>\n",
       "      <td>0.487805</td>\n",
       "      <td>0.402439</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.419753</td>\n",
       "      <td>0.465793</td>\n",
       "      <td>0.054187</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.056111</td>\n",
       "      <td>0.003324</td>\n",
       "      <td>0.001302</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>gini</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>random</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 10, 'min_sa...</td>\n",
       "      <td>0.524390</td>\n",
       "      <td>0.609756</td>\n",
       "      <td>0.512195</td>\n",
       "      <td>0.518519</td>\n",
       "      <td>0.506173</td>\n",
       "      <td>0.534207</td>\n",
       "      <td>0.038264</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.565747</td>\n",
       "      <td>0.041128</td>\n",
       "      <td>0.001312</td>\n",
       "      <td>0.000059</td>\n",
       "      <td>gini</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>best</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 10, 'min_sa...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.475610</td>\n",
       "      <td>0.463415</td>\n",
       "      <td>0.543210</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.485336</td>\n",
       "      <td>0.034093</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.060230</td>\n",
       "      <td>0.003229</td>\n",
       "      <td>0.001351</td>\n",
       "      <td>0.000070</td>\n",
       "      <td>gini</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>random</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 10, 'min_sa...</td>\n",
       "      <td>0.512195</td>\n",
       "      <td>0.426829</td>\n",
       "      <td>0.524390</td>\n",
       "      <td>0.506173</td>\n",
       "      <td>0.481481</td>\n",
       "      <td>0.490214</td>\n",
       "      <td>0.034640</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.573539</td>\n",
       "      <td>0.036635</td>\n",
       "      <td>0.001431</td>\n",
       "      <td>0.000133</td>\n",
       "      <td>gini</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>best</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 10, 'min_sa...</td>\n",
       "      <td>0.402439</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.451220</td>\n",
       "      <td>0.592593</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.478139</td>\n",
       "      <td>0.065066</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.069387</td>\n",
       "      <td>0.005290</td>\n",
       "      <td>0.001837</td>\n",
       "      <td>0.001035</td>\n",
       "      <td>entropy</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>random</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': None, 'm...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.463415</td>\n",
       "      <td>0.487805</td>\n",
       "      <td>0.506173</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.502590</td>\n",
       "      <td>0.030260</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.750811</td>\n",
       "      <td>0.055675</td>\n",
       "      <td>0.001381</td>\n",
       "      <td>0.000174</td>\n",
       "      <td>entropy</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>best</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': None, 'm...</td>\n",
       "      <td>0.524390</td>\n",
       "      <td>0.548780</td>\n",
       "      <td>0.487805</td>\n",
       "      <td>0.456790</td>\n",
       "      <td>0.493827</td>\n",
       "      <td>0.502319</td>\n",
       "      <td>0.031627</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.065690</td>\n",
       "      <td>0.001404</td>\n",
       "      <td>0.001268</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>entropy</td>\n",
       "      <td>None</td>\n",
       "      <td>5</td>\n",
       "      <td>random</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': None, 'm...</td>\n",
       "      <td>0.560976</td>\n",
       "      <td>0.524390</td>\n",
       "      <td>0.426829</td>\n",
       "      <td>0.543210</td>\n",
       "      <td>0.543210</td>\n",
       "      <td>0.519723</td>\n",
       "      <td>0.047867</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.726038</td>\n",
       "      <td>0.047872</td>\n",
       "      <td>0.001302</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>entropy</td>\n",
       "      <td>None</td>\n",
       "      <td>5</td>\n",
       "      <td>best</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': None, 'm...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.536585</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.493827</td>\n",
       "      <td>0.506173</td>\n",
       "      <td>0.507317</td>\n",
       "      <td>0.015146</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.033533</td>\n",
       "      <td>0.000782</td>\n",
       "      <td>0.001392</td>\n",
       "      <td>0.000148</td>\n",
       "      <td>entropy</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>random</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 5, 'min_...</td>\n",
       "      <td>0.451220</td>\n",
       "      <td>0.512195</td>\n",
       "      <td>0.548780</td>\n",
       "      <td>0.530864</td>\n",
       "      <td>0.518519</td>\n",
       "      <td>0.512316</td>\n",
       "      <td>0.033000</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.561938</td>\n",
       "      <td>0.020931</td>\n",
       "      <td>0.001269</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>entropy</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>best</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 5, 'min_...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.524390</td>\n",
       "      <td>0.487805</td>\n",
       "      <td>0.469136</td>\n",
       "      <td>0.407407</td>\n",
       "      <td>0.477748</td>\n",
       "      <td>0.039481</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.040175</td>\n",
       "      <td>0.004643</td>\n",
       "      <td>0.001279</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>entropy</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>random</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 5, 'min_...</td>\n",
       "      <td>0.524390</td>\n",
       "      <td>0.487805</td>\n",
       "      <td>0.463415</td>\n",
       "      <td>0.518519</td>\n",
       "      <td>0.518519</td>\n",
       "      <td>0.502529</td>\n",
       "      <td>0.023392</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.556797</td>\n",
       "      <td>0.022564</td>\n",
       "      <td>0.001336</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>entropy</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>best</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 5, 'min_...</td>\n",
       "      <td>0.512195</td>\n",
       "      <td>0.524390</td>\n",
       "      <td>0.487805</td>\n",
       "      <td>0.530864</td>\n",
       "      <td>0.419753</td>\n",
       "      <td>0.495002</td>\n",
       "      <td>0.040397</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.056171</td>\n",
       "      <td>0.001633</td>\n",
       "      <td>0.001280</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>entropy</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>random</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 10, 'min...</td>\n",
       "      <td>0.451220</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.463415</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.518519</td>\n",
       "      <td>0.475519</td>\n",
       "      <td>0.028813</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1.017197</td>\n",
       "      <td>0.376954</td>\n",
       "      <td>0.001961</td>\n",
       "      <td>0.000558</td>\n",
       "      <td>entropy</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>best</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 10, 'min...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.536585</td>\n",
       "      <td>0.512195</td>\n",
       "      <td>0.530864</td>\n",
       "      <td>0.493827</td>\n",
       "      <td>0.514694</td>\n",
       "      <td>0.016723</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.059406</td>\n",
       "      <td>0.002331</td>\n",
       "      <td>0.001336</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>entropy</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>random</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 10, 'min...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.634146</td>\n",
       "      <td>0.419753</td>\n",
       "      <td>0.530864</td>\n",
       "      <td>0.516953</td>\n",
       "      <td>0.069210</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1.109024</td>\n",
       "      <td>0.440513</td>\n",
       "      <td>0.001997</td>\n",
       "      <td>0.000551</td>\n",
       "      <td>entropy</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>best</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 10, 'min...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.536585</td>\n",
       "      <td>0.487805</td>\n",
       "      <td>0.493827</td>\n",
       "      <td>0.493827</td>\n",
       "      <td>0.502409</td>\n",
       "      <td>0.017518</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.074169</td>\n",
       "      <td>0.011198</td>\n",
       "      <td>0.001393</td>\n",
       "      <td>0.000134</td>\n",
       "      <td>log_loss</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>random</td>\n",
       "      <td>{'criterion': 'log_loss', 'max_depth': None, '...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.475610</td>\n",
       "      <td>0.524390</td>\n",
       "      <td>0.456790</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.502469</td>\n",
       "      <td>0.034965</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1.490446</td>\n",
       "      <td>0.236050</td>\n",
       "      <td>0.002961</td>\n",
       "      <td>0.000858</td>\n",
       "      <td>log_loss</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>best</td>\n",
       "      <td>{'criterion': 'log_loss', 'max_depth': None, '...</td>\n",
       "      <td>0.487805</td>\n",
       "      <td>0.548780</td>\n",
       "      <td>0.536585</td>\n",
       "      <td>0.506173</td>\n",
       "      <td>0.493827</td>\n",
       "      <td>0.514634</td>\n",
       "      <td>0.023967</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.146871</td>\n",
       "      <td>0.011497</td>\n",
       "      <td>0.002525</td>\n",
       "      <td>0.000221</td>\n",
       "      <td>log_loss</td>\n",
       "      <td>None</td>\n",
       "      <td>5</td>\n",
       "      <td>random</td>\n",
       "      <td>{'criterion': 'log_loss', 'max_depth': None, '...</td>\n",
       "      <td>0.463415</td>\n",
       "      <td>0.475610</td>\n",
       "      <td>0.536585</td>\n",
       "      <td>0.617284</td>\n",
       "      <td>0.456790</td>\n",
       "      <td>0.509937</td>\n",
       "      <td>0.060664</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1.611278</td>\n",
       "      <td>0.205888</td>\n",
       "      <td>0.002112</td>\n",
       "      <td>0.000721</td>\n",
       "      <td>log_loss</td>\n",
       "      <td>None</td>\n",
       "      <td>5</td>\n",
       "      <td>best</td>\n",
       "      <td>{'criterion': 'log_loss', 'max_depth': None, '...</td>\n",
       "      <td>0.536585</td>\n",
       "      <td>0.536585</td>\n",
       "      <td>0.548780</td>\n",
       "      <td>0.481481</td>\n",
       "      <td>0.530864</td>\n",
       "      <td>0.526859</td>\n",
       "      <td>0.023430</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.086913</td>\n",
       "      <td>0.010936</td>\n",
       "      <td>0.002651</td>\n",
       "      <td>0.000265</td>\n",
       "      <td>log_loss</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>random</td>\n",
       "      <td>{'criterion': 'log_loss', 'max_depth': 5, 'min...</td>\n",
       "      <td>0.536585</td>\n",
       "      <td>0.475610</td>\n",
       "      <td>0.487805</td>\n",
       "      <td>0.580247</td>\n",
       "      <td>0.543210</td>\n",
       "      <td>0.524691</td>\n",
       "      <td>0.038316</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1.195796</td>\n",
       "      <td>0.092512</td>\n",
       "      <td>0.002093</td>\n",
       "      <td>0.000542</td>\n",
       "      <td>log_loss</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>best</td>\n",
       "      <td>{'criterion': 'log_loss', 'max_depth': 5, 'min...</td>\n",
       "      <td>0.512195</td>\n",
       "      <td>0.524390</td>\n",
       "      <td>0.487805</td>\n",
       "      <td>0.506173</td>\n",
       "      <td>0.419753</td>\n",
       "      <td>0.490063</td>\n",
       "      <td>0.037084</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.075279</td>\n",
       "      <td>0.004806</td>\n",
       "      <td>0.002444</td>\n",
       "      <td>0.000059</td>\n",
       "      <td>log_loss</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>random</td>\n",
       "      <td>{'criterion': 'log_loss', 'max_depth': 5, 'min...</td>\n",
       "      <td>0.524390</td>\n",
       "      <td>0.512195</td>\n",
       "      <td>0.560976</td>\n",
       "      <td>0.432099</td>\n",
       "      <td>0.469136</td>\n",
       "      <td>0.499759</td>\n",
       "      <td>0.044776</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.906817</td>\n",
       "      <td>0.278387</td>\n",
       "      <td>0.001428</td>\n",
       "      <td>0.000173</td>\n",
       "      <td>log_loss</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>best</td>\n",
       "      <td>{'criterion': 'log_loss', 'max_depth': 5, 'min...</td>\n",
       "      <td>0.524390</td>\n",
       "      <td>0.524390</td>\n",
       "      <td>0.487805</td>\n",
       "      <td>0.518519</td>\n",
       "      <td>0.432099</td>\n",
       "      <td>0.497441</td>\n",
       "      <td>0.035381</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.123204</td>\n",
       "      <td>0.007578</td>\n",
       "      <td>0.002369</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>log_loss</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>random</td>\n",
       "      <td>{'criterion': 'log_loss', 'max_depth': 10, 'mi...</td>\n",
       "      <td>0.609756</td>\n",
       "      <td>0.451220</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.407407</td>\n",
       "      <td>0.482565</td>\n",
       "      <td>0.070094</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.767470</td>\n",
       "      <td>0.077410</td>\n",
       "      <td>0.001320</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>log_loss</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>best</td>\n",
       "      <td>{'criterion': 'log_loss', 'max_depth': 10, 'mi...</td>\n",
       "      <td>0.548780</td>\n",
       "      <td>0.524390</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.518519</td>\n",
       "      <td>0.518519</td>\n",
       "      <td>0.522042</td>\n",
       "      <td>0.015692</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.057612</td>\n",
       "      <td>0.003268</td>\n",
       "      <td>0.001254</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>log_loss</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>random</td>\n",
       "      <td>{'criterion': 'log_loss', 'max_depth': 10, 'mi...</td>\n",
       "      <td>0.463415</td>\n",
       "      <td>0.414634</td>\n",
       "      <td>0.585366</td>\n",
       "      <td>0.493827</td>\n",
       "      <td>0.518519</td>\n",
       "      <td>0.495152</td>\n",
       "      <td>0.056880</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.618485</td>\n",
       "      <td>0.043825</td>\n",
       "      <td>0.000899</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>log_loss</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>best</td>\n",
       "      <td>{'criterion': 'log_loss', 'max_depth': 10, 'mi...</td>\n",
       "      <td>0.560976</td>\n",
       "      <td>0.560976</td>\n",
       "      <td>0.475610</td>\n",
       "      <td>0.518519</td>\n",
       "      <td>0.481481</td>\n",
       "      <td>0.519512</td>\n",
       "      <td>0.036914</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0        0.102667      0.006733         0.001422        0.000089   \n",
       "1        0.624601      0.068204         0.001910        0.001181   \n",
       "2        0.075625      0.007734         0.001738        0.000854   \n",
       "3        0.602447      0.059214         0.001295        0.000075   \n",
       "4        0.046888      0.013620         0.001339        0.000091   \n",
       "5        0.425438      0.008953         0.001300        0.000069   \n",
       "6        0.039107      0.006686         0.001293        0.000070   \n",
       "7        0.415766      0.004519         0.001346        0.000034   \n",
       "8        0.056111      0.003324         0.001302        0.000045   \n",
       "9        0.565747      0.041128         0.001312        0.000059   \n",
       "10       0.060230      0.003229         0.001351        0.000070   \n",
       "11       0.573539      0.036635         0.001431        0.000133   \n",
       "12       0.069387      0.005290         0.001837        0.001035   \n",
       "13       0.750811      0.055675         0.001381        0.000174   \n",
       "14       0.065690      0.001404         0.001268        0.000046   \n",
       "15       0.726038      0.047872         0.001302        0.000047   \n",
       "16       0.033533      0.000782         0.001392        0.000148   \n",
       "17       0.561938      0.020931         0.001269        0.000023   \n",
       "18       0.040175      0.004643         0.001279        0.000066   \n",
       "19       0.556797      0.022564         0.001336        0.000053   \n",
       "20       0.056171      0.001633         0.001280        0.000050   \n",
       "21       1.017197      0.376954         0.001961        0.000558   \n",
       "22       0.059406      0.002331         0.001336        0.000036   \n",
       "23       1.109024      0.440513         0.001997        0.000551   \n",
       "24       0.074169      0.011198         0.001393        0.000134   \n",
       "25       1.490446      0.236050         0.002961        0.000858   \n",
       "26       0.146871      0.011497         0.002525        0.000221   \n",
       "27       1.611278      0.205888         0.002112        0.000721   \n",
       "28       0.086913      0.010936         0.002651        0.000265   \n",
       "29       1.195796      0.092512         0.002093        0.000542   \n",
       "30       0.075279      0.004806         0.002444        0.000059   \n",
       "31       0.906817      0.278387         0.001428        0.000173   \n",
       "32       0.123204      0.007578         0.002369        0.000019   \n",
       "33       0.767470      0.077410         0.001320        0.000024   \n",
       "34       0.057612      0.003268         0.001254        0.000044   \n",
       "35       0.618485      0.043825         0.000899        0.000051   \n",
       "\n",
       "   param_criterion param_max_depth param_min_samples_split param_splitter  \\\n",
       "0             gini            None                       2         random   \n",
       "1             gini            None                       2           best   \n",
       "2             gini            None                       5         random   \n",
       "3             gini            None                       5           best   \n",
       "4             gini               5                       2         random   \n",
       "5             gini               5                       2           best   \n",
       "6             gini               5                       5         random   \n",
       "7             gini               5                       5           best   \n",
       "8             gini              10                       2         random   \n",
       "9             gini              10                       2           best   \n",
       "10            gini              10                       5         random   \n",
       "11            gini              10                       5           best   \n",
       "12         entropy            None                       2         random   \n",
       "13         entropy            None                       2           best   \n",
       "14         entropy            None                       5         random   \n",
       "15         entropy            None                       5           best   \n",
       "16         entropy               5                       2         random   \n",
       "17         entropy               5                       2           best   \n",
       "18         entropy               5                       5         random   \n",
       "19         entropy               5                       5           best   \n",
       "20         entropy              10                       2         random   \n",
       "21         entropy              10                       2           best   \n",
       "22         entropy              10                       5         random   \n",
       "23         entropy              10                       5           best   \n",
       "24        log_loss            None                       2         random   \n",
       "25        log_loss            None                       2           best   \n",
       "26        log_loss            None                       5         random   \n",
       "27        log_loss            None                       5           best   \n",
       "28        log_loss               5                       2         random   \n",
       "29        log_loss               5                       2           best   \n",
       "30        log_loss               5                       5         random   \n",
       "31        log_loss               5                       5           best   \n",
       "32        log_loss              10                       2         random   \n",
       "33        log_loss              10                       2           best   \n",
       "34        log_loss              10                       5         random   \n",
       "35        log_loss              10                       5           best   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "0   {'criterion': 'gini', 'max_depth': None, 'min_...           0.548780   \n",
       "1   {'criterion': 'gini', 'max_depth': None, 'min_...           0.341463   \n",
       "2   {'criterion': 'gini', 'max_depth': None, 'min_...           0.463415   \n",
       "3   {'criterion': 'gini', 'max_depth': None, 'min_...           0.500000   \n",
       "4   {'criterion': 'gini', 'max_depth': 5, 'min_sam...           0.500000   \n",
       "5   {'criterion': 'gini', 'max_depth': 5, 'min_sam...           0.475610   \n",
       "6   {'criterion': 'gini', 'max_depth': 5, 'min_sam...           0.536585   \n",
       "7   {'criterion': 'gini', 'max_depth': 5, 'min_sam...           0.463415   \n",
       "8   {'criterion': 'gini', 'max_depth': 10, 'min_sa...           0.524390   \n",
       "9   {'criterion': 'gini', 'max_depth': 10, 'min_sa...           0.500000   \n",
       "10  {'criterion': 'gini', 'max_depth': 10, 'min_sa...           0.512195   \n",
       "11  {'criterion': 'gini', 'max_depth': 10, 'min_sa...           0.402439   \n",
       "12  {'criterion': 'entropy', 'max_depth': None, 'm...           0.500000   \n",
       "13  {'criterion': 'entropy', 'max_depth': None, 'm...           0.524390   \n",
       "14  {'criterion': 'entropy', 'max_depth': None, 'm...           0.560976   \n",
       "15  {'criterion': 'entropy', 'max_depth': None, 'm...           0.500000   \n",
       "16  {'criterion': 'entropy', 'max_depth': 5, 'min_...           0.451220   \n",
       "17  {'criterion': 'entropy', 'max_depth': 5, 'min_...           0.500000   \n",
       "18  {'criterion': 'entropy', 'max_depth': 5, 'min_...           0.524390   \n",
       "19  {'criterion': 'entropy', 'max_depth': 5, 'min_...           0.512195   \n",
       "20  {'criterion': 'entropy', 'max_depth': 10, 'min...           0.451220   \n",
       "21  {'criterion': 'entropy', 'max_depth': 10, 'min...           0.500000   \n",
       "22  {'criterion': 'entropy', 'max_depth': 10, 'min...           0.500000   \n",
       "23  {'criterion': 'entropy', 'max_depth': 10, 'min...           0.500000   \n",
       "24  {'criterion': 'log_loss', 'max_depth': None, '...           0.500000   \n",
       "25  {'criterion': 'log_loss', 'max_depth': None, '...           0.487805   \n",
       "26  {'criterion': 'log_loss', 'max_depth': None, '...           0.463415   \n",
       "27  {'criterion': 'log_loss', 'max_depth': None, '...           0.536585   \n",
       "28  {'criterion': 'log_loss', 'max_depth': 5, 'min...           0.536585   \n",
       "29  {'criterion': 'log_loss', 'max_depth': 5, 'min...           0.512195   \n",
       "30  {'criterion': 'log_loss', 'max_depth': 5, 'min...           0.524390   \n",
       "31  {'criterion': 'log_loss', 'max_depth': 5, 'min...           0.524390   \n",
       "32  {'criterion': 'log_loss', 'max_depth': 10, 'mi...           0.609756   \n",
       "33  {'criterion': 'log_loss', 'max_depth': 10, 'mi...           0.548780   \n",
       "34  {'criterion': 'log_loss', 'max_depth': 10, 'mi...           0.463415   \n",
       "35  {'criterion': 'log_loss', 'max_depth': 10, 'mi...           0.560976   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0            0.475610           0.463415           0.469136   \n",
       "1            0.512195           0.475610           0.567901   \n",
       "2            0.560976           0.439024           0.469136   \n",
       "3            0.451220           0.463415           0.617284   \n",
       "4            0.560976           0.548780           0.543210   \n",
       "5            0.402439           0.426829           0.580247   \n",
       "6            0.463415           0.536585           0.518519   \n",
       "7            0.487805           0.402439           0.555556   \n",
       "8            0.609756           0.512195           0.518519   \n",
       "9            0.475610           0.463415           0.543210   \n",
       "10           0.426829           0.524390           0.506173   \n",
       "11           0.500000           0.451220           0.592593   \n",
       "12           0.463415           0.487805           0.506173   \n",
       "13           0.548780           0.487805           0.456790   \n",
       "14           0.524390           0.426829           0.543210   \n",
       "15           0.536585           0.500000           0.493827   \n",
       "16           0.512195           0.548780           0.530864   \n",
       "17           0.524390           0.487805           0.469136   \n",
       "18           0.487805           0.463415           0.518519   \n",
       "19           0.524390           0.487805           0.530864   \n",
       "20           0.500000           0.463415           0.444444   \n",
       "21           0.536585           0.512195           0.530864   \n",
       "22           0.500000           0.634146           0.419753   \n",
       "23           0.536585           0.487805           0.493827   \n",
       "24           0.475610           0.524390           0.456790   \n",
       "25           0.548780           0.536585           0.506173   \n",
       "26           0.475610           0.536585           0.617284   \n",
       "27           0.536585           0.548780           0.481481   \n",
       "28           0.475610           0.487805           0.580247   \n",
       "29           0.524390           0.487805           0.506173   \n",
       "30           0.512195           0.560976           0.432099   \n",
       "31           0.524390           0.487805           0.518519   \n",
       "32           0.451220           0.500000           0.444444   \n",
       "33           0.524390           0.500000           0.518519   \n",
       "34           0.414634           0.585366           0.493827   \n",
       "35           0.560976           0.475610           0.518519   \n",
       "\n",
       "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0            0.493827         0.490154        0.031045               27  \n",
       "1            0.481481         0.475730        0.074680               33  \n",
       "2            0.530864         0.492683        0.045633               24  \n",
       "3            0.419753         0.490334        0.068478               25  \n",
       "4            0.419753         0.514544        0.051665               10  \n",
       "5            0.456790         0.468383        0.061279               35  \n",
       "6            0.481481         0.507317        0.029778               13  \n",
       "7            0.419753         0.465793        0.054187               36  \n",
       "8            0.506173         0.534207        0.038264                1  \n",
       "9            0.444444         0.485336        0.034093               29  \n",
       "10           0.481481         0.490214        0.034640               26  \n",
       "11           0.444444         0.478139        0.065066               31  \n",
       "12           0.555556         0.502590        0.030260               15  \n",
       "13           0.493827         0.502319        0.031627               19  \n",
       "14           0.543210         0.519723        0.047867                5  \n",
       "15           0.506173         0.507317        0.015146               13  \n",
       "16           0.518519         0.512316        0.033000               11  \n",
       "17           0.407407         0.477748        0.039481               32  \n",
       "18           0.518519         0.502529        0.023392               16  \n",
       "19           0.419753         0.495002        0.040397               23  \n",
       "20           0.518519         0.475519        0.028813               34  \n",
       "21           0.493827         0.514694        0.016723                8  \n",
       "22           0.530864         0.516953        0.069210                7  \n",
       "23           0.493827         0.502409        0.017518               18  \n",
       "24           0.555556         0.502469        0.034965               17  \n",
       "25           0.493827         0.514634        0.023967                9  \n",
       "26           0.456790         0.509937        0.060664               12  \n",
       "27           0.530864         0.526859        0.023430                2  \n",
       "28           0.543210         0.524691        0.038316                3  \n",
       "29           0.419753         0.490063        0.037084               28  \n",
       "30           0.469136         0.499759        0.044776               20  \n",
       "31           0.432099         0.497441        0.035381               21  \n",
       "32           0.407407         0.482565        0.070094               30  \n",
       "33           0.518519         0.522042        0.015692                4  \n",
       "34           0.518519         0.495152        0.056880               22  \n",
       "35           0.481481         0.519512        0.036914                6  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def classifier_select(fselect):\n",
    "    \n",
    "    # KNeighborsClassifier\n",
    "    if fselect == 1:\n",
    "\n",
    "        knn_params=[{'n_neighbors':[1,3,5,7,9,11], 'weights': ['uniform', 'distance'], 'p':[1,2]}]\n",
    "        knn = KNeighborsClassifier()\n",
    "        \n",
    "        return knn_params, knn\n",
    "        \n",
    "    # Naive Bayes\n",
    "    elif fselect == 2:\n",
    "        \n",
    "        nb_params=[{'var_smoothing':[1e-09,1e-03, 1e-06]}]\n",
    "        nb = GaussianNB()\n",
    "    \n",
    "        return nb_params, nb\n",
    "        \n",
    "    # Decision Tree\n",
    "    elif fselect == 3:\n",
    "        \n",
    "        dc_params=[{'criterion':['gini', 'entropy', 'log_loss'],\n",
    "            'max_depth': [None, 5, 10],\n",
    "            'min_samples_split':[2, 5],\n",
    "            'splitter':['random', 'best']}] \n",
    "        dt = DecisionTreeClassifier()\n",
    "        \n",
    "        return dc_params, dt\n",
    "        \n",
    "    # Multilayer perceptron\n",
    "    elif fselect == 4:\n",
    "        \n",
    "        mlp_params=[{'hidden_layer_sizes':[16, (16, 8), (16, 8, 4)],\n",
    "                   'learning_rate': ['constant', 'invscaling'],\n",
    "                    'learning_rate_init':[0.01, 0.001, 0.0001],\n",
    "                    'activation':['relu', 'logistic', 'tanh'],\n",
    "                   'random_state':[10, 46, 37]}] \n",
    "        mlp = MLPClassifier()\n",
    "        \n",
    "        return mlp_params, mlp \n",
    "        \n",
    "    # Support Vector Machine\n",
    "    else:\n",
    "        svm_params=[{'kernel':[\"linear\", \"poly\"]}]\n",
    "        svm = SVC()\n",
    "        \n",
    "        return svm_params, svm\n",
    "\n",
    "params, clf = classifier_select(3)\n",
    "    \n",
    "X,X_val,y,y_val = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "\n",
    "gs=GridSearchCV(clf, params, scoring='accuracy', cv=5, n_jobs=-1)\n",
    "\n",
    "gs.fit(X_val, y_val)\n",
    "\n",
    "df=gs.cv_results_\n",
    "df = pd.DataFrame(gs.cv_results_)\n",
    "print(\"Melhores par√¢metros encontrados: \", gs.best_params_)\n",
    "\n",
    "clf = gs.best_estimator_\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f354830d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X_all\n",
    "y = y_all\n",
    "\n",
    "num = []\n",
    "\n",
    "for i in range(5):\n",
    "    params, clf = classifier_select(i + 1)\n",
    "    num.append(clf)\n",
    "\n",
    "def ensemble_select(fselect, fnum):\n",
    "    \n",
    "    if fselect == 1:\n",
    "        adc = AdaBoostClassifier()\n",
    "        adc_params = [{'estimator': fnum, \n",
    "                       'n_estimators': [10, 25, 50, 75, 100], \n",
    "                       'learning_rate': [0.7, 0.8, 1]}] \n",
    "        \n",
    "        return adc, adc_params\n",
    "\n",
    "    elif fselect == 2:\n",
    "        rfc = RandomForestClassifier()\n",
    "        rfc_params = [{'n_estimators': [10, 25, 50, 75, 100], \n",
    "                       \"criterion\": [\"gini\", 'entropy', \"log_loss\"], \n",
    "                       \"max_depth\": [10, 11, 12]}]\n",
    "        \n",
    "        return rfc, rfc_params\n",
    "    \n",
    "    else:\n",
    "        bg = BaggingClassifier()\n",
    "        bg_params = [{'estimator': fnum, \n",
    "                      'n_estimators': [10, 25, 50, 75, 100], \n",
    "                      'max_samples': [0.7, 0.8, 1]}]\n",
    "        \n",
    "        return bg, bg_params\n",
    "        \n",
    "\n",
    "clf, params = ensemble_select(2, num)\n",
    "\n",
    "X,X_val,y,y_val=train_test_split(X,y,test_size=0.2,random_state=42, stratify=y)\n",
    "\n",
    "gs=GridSearchCV(clf, params, scoring='accuracy', cv=5, n_jobs=-1)\n",
    "\n",
    "gs.fit(X_val, y_val)\n",
    "\n",
    "df=gs.cv_results_\n",
    "df = pd.DataFrame(gs.cv_results_)\n",
    "print(\"Melhores par√¢metros encontrados: \", gs.best_params_)\n",
    "\n",
    "clf=gs.best_estimator_\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "63e28d18",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acur√°cia m√©dia: 0.528\n",
      "Desvio padr√£o: 0.026\n",
      "Precision: 0.523\n",
      "Recall: 0.522\n",
      "f1: 0.522\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7f8b7d5f0280>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result=model_selection.cross_val_score(clf, X, y, cv=5)\n",
    "print(\"Acur√°cia m√©dia: %.3f\" % result.mean())\n",
    "print(\"Desvio padr√£o: %.3f\" % result.std())\n",
    "\n",
    "# Calculando a predi√ß√£o para cada exemplo de teste\n",
    "y_pred=model_selection.cross_val_predict(clf, X, y, cv=5)\n",
    "\n",
    "# Calcular precis√£o\n",
    "precision=precision_score(y, y_pred, average='macro')\n",
    "\n",
    "# Calcular revoca√ß√£o\n",
    "recall=recall_score(y, y_pred, average='macro')\n",
    "\n",
    "# Calcular revoca√ß√£o\n",
    "f1=f1_score(y, y_pred, average='macro')\n",
    "\n",
    "print(\"Precision: %.3f\" % precision)\n",
    "print(\"Recall: %.3f\" % recall)\n",
    "print(\"f1: %.3f\" % f1)\n",
    "\n",
    "cm = confusion_matrix(y, y_pred, labels=clf.classes_)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53aaecf9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
