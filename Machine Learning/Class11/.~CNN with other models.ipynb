{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "300bfcdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Classifiers and Ensembles\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "# Metrics\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0352c21e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2040,)\n",
      "(2040, 2048)\n",
      "(2040,)\n"
     ]
    }
   ],
   "source": [
    "# Labels\n",
    "y = pd.read_csv('y_im.csv', header=None)\n",
    "y=y.to_numpy()\n",
    "y=np.ravel(y)\n",
    "print(y.shape)\n",
    "\n",
    "# deep features\n",
    "X = pd.read_csv('X_im.csv', header=None)\n",
    "X=X.to_numpy()\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2aabc060",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhores parâmetros encontrados:  {'var_smoothing': 1e-09}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_var_smoothing</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.042336</td>\n",
       "      <td>0.001847</td>\n",
       "      <td>0.009717</td>\n",
       "      <td>0.000313</td>\n",
       "      <td>0.0</td>\n",
       "      <td>{'var_smoothing': 1e-09}</td>\n",
       "      <td>0.609756</td>\n",
       "      <td>0.463415</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.543210</td>\n",
       "      <td>0.534387</td>\n",
       "      <td>0.049852</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.045358</td>\n",
       "      <td>0.003902</td>\n",
       "      <td>0.008010</td>\n",
       "      <td>0.001714</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'var_smoothing': 0.001}</td>\n",
       "      <td>0.585366</td>\n",
       "      <td>0.463415</td>\n",
       "      <td>0.487805</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.530864</td>\n",
       "      <td>0.524601</td>\n",
       "      <td>0.044244</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.041378</td>\n",
       "      <td>0.004028</td>\n",
       "      <td>0.006464</td>\n",
       "      <td>0.001166</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>{'var_smoothing': 1e-06}</td>\n",
       "      <td>0.597561</td>\n",
       "      <td>0.463415</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.543210</td>\n",
       "      <td>0.531948</td>\n",
       "      <td>0.046275</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       0.042336      0.001847         0.009717        0.000313   \n",
       "1       0.045358      0.003902         0.008010        0.001714   \n",
       "2       0.041378      0.004028         0.006464        0.001166   \n",
       "\n",
       "  param_var_smoothing                    params  split0_test_score  \\\n",
       "0                 0.0  {'var_smoothing': 1e-09}           0.609756   \n",
       "1               0.001  {'var_smoothing': 0.001}           0.585366   \n",
       "2            0.000001  {'var_smoothing': 1e-06}           0.597561   \n",
       "\n",
       "   split1_test_score  split2_test_score  split3_test_score  split4_test_score  \\\n",
       "0           0.463415           0.500000           0.555556           0.543210   \n",
       "1           0.463415           0.487805           0.555556           0.530864   \n",
       "2           0.463415           0.500000           0.555556           0.543210   \n",
       "\n",
       "   mean_test_score  std_test_score  rank_test_score  \n",
       "0         0.534387        0.049852                1  \n",
       "1         0.524601        0.044244                3  \n",
       "2         0.531948        0.046275                2  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def classifier_select(fselect):\n",
    "    \n",
    "    # KNeighborsClassifier\n",
    "    if fselect == 1:\n",
    "\n",
    "        knn_params=[{'n_neighbors':[1,3,5,7,9,11], 'weights': ['uniform', 'distance'], 'p':[1,2]}]\n",
    "        knn = KNeighborsClassifier()\n",
    "        \n",
    "        return knn_params, knn\n",
    "        \n",
    "    # Naive Bayes\n",
    "    elif fselect == 2:\n",
    "        \n",
    "        nb_params=[{'var_smoothing':[1e-09,1e-03, 1e-06]}]\n",
    "        nb = GaussianNB()\n",
    "    \n",
    "        return nb_params, nb\n",
    "        \n",
    "    # Decision Tree\n",
    "    elif fselect == 3:\n",
    "        \n",
    "        dc_params=[{'criterion':['gini', 'entropy', 'log_loss'],\n",
    "            'max_depth': [None, 5, 10],\n",
    "            'min_samples_split':[2, 5],\n",
    "            'splitter':['random', 'best']}] \n",
    "        dt = DecisionTreeClassifier()\n",
    "        \n",
    "        return dc_params, dt\n",
    "        \n",
    "    # Multilayer perceptron\n",
    "    elif fselect == 4:\n",
    "        \n",
    "        mlp_params=[{'hidden_layer_sizes':[16, (16, 8), (16, 8, 4)],\n",
    "                   'learning_rate': ['constant', 'invscaling'],\n",
    "                    'learning_rate_init':[0.01, 0.001, 0.0001],\n",
    "                    'activation':['relu', 'logistic', 'tanh'],\n",
    "                   'random_state':[10, 46, 37]}] \n",
    "        mlp = MLPClassifier()\n",
    "        \n",
    "        return mlp_params, mlp \n",
    "        \n",
    "    # Support Vector Machine\n",
    "    else:\n",
    "        svm_params=[{'kernel':[\"linear\", \"poly\"]}]\n",
    "        svm = SVC()\n",
    "        \n",
    "        return svm_params, svm\n",
    "\n",
    "params, clf = classifier_select(2)\n",
    "    \n",
    "X,X_val,y,y_val = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "\n",
    "gs=GridSearchCV(clf, params, scoring='accuracy', cv=5, n_jobs=-1)\n",
    "\n",
    "gs.fit(X_val, y_val)\n",
    "\n",
    "df=gs.cv_results_\n",
    "df = pd.DataFrame(gs.cv_results_)\n",
    "print(\"Melhores parâmetros encontrados: \", gs.best_params_)\n",
    "\n",
    "clf = gs.best_estimator_\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f354830d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhores parâmetros encontrados:  {'criterion': 'log_loss', 'max_depth': 12, 'n_estimators': 75}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_criterion</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.051290</td>\n",
       "      <td>0.005361</td>\n",
       "      <td>0.003976</td>\n",
       "      <td>0.000569</td>\n",
       "      <td>gini</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 10, 'n_esti...</td>\n",
       "      <td>0.940541</td>\n",
       "      <td>0.891304</td>\n",
       "      <td>0.923913</td>\n",
       "      <td>0.902174</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.906586</td>\n",
       "      <td>0.023254</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.089697</td>\n",
       "      <td>0.004951</td>\n",
       "      <td>0.003454</td>\n",
       "      <td>0.002394</td>\n",
       "      <td>gini</td>\n",
       "      <td>10</td>\n",
       "      <td>25</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 10, 'n_esti...</td>\n",
       "      <td>0.956757</td>\n",
       "      <td>0.907609</td>\n",
       "      <td>0.945652</td>\n",
       "      <td>0.940217</td>\n",
       "      <td>0.896739</td>\n",
       "      <td>0.929395</td>\n",
       "      <td>0.023113</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.188713</td>\n",
       "      <td>0.010927</td>\n",
       "      <td>0.010764</td>\n",
       "      <td>0.002466</td>\n",
       "      <td>gini</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 10, 'n_esti...</td>\n",
       "      <td>0.945946</td>\n",
       "      <td>0.880435</td>\n",
       "      <td>0.961957</td>\n",
       "      <td>0.929348</td>\n",
       "      <td>0.902174</td>\n",
       "      <td>0.923972</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.286051</td>\n",
       "      <td>0.019875</td>\n",
       "      <td>0.009791</td>\n",
       "      <td>0.000506</td>\n",
       "      <td>gini</td>\n",
       "      <td>10</td>\n",
       "      <td>75</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 10, 'n_esti...</td>\n",
       "      <td>0.940541</td>\n",
       "      <td>0.907609</td>\n",
       "      <td>0.961957</td>\n",
       "      <td>0.934783</td>\n",
       "      <td>0.896739</td>\n",
       "      <td>0.928325</td>\n",
       "      <td>0.023447</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.365269</td>\n",
       "      <td>0.010018</td>\n",
       "      <td>0.014212</td>\n",
       "      <td>0.001676</td>\n",
       "      <td>gini</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 10, 'n_esti...</td>\n",
       "      <td>0.935135</td>\n",
       "      <td>0.891304</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.934783</td>\n",
       "      <td>0.885870</td>\n",
       "      <td>0.920723</td>\n",
       "      <td>0.027449</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.033946</td>\n",
       "      <td>0.001539</td>\n",
       "      <td>0.002199</td>\n",
       "      <td>0.000411</td>\n",
       "      <td>gini</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 11, 'n_esti...</td>\n",
       "      <td>0.929730</td>\n",
       "      <td>0.880435</td>\n",
       "      <td>0.923913</td>\n",
       "      <td>0.929348</td>\n",
       "      <td>0.896739</td>\n",
       "      <td>0.912033</td>\n",
       "      <td>0.019932</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.093932</td>\n",
       "      <td>0.007733</td>\n",
       "      <td>0.005180</td>\n",
       "      <td>0.001043</td>\n",
       "      <td>gini</td>\n",
       "      <td>11</td>\n",
       "      <td>25</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 11, 'n_esti...</td>\n",
       "      <td>0.940541</td>\n",
       "      <td>0.891304</td>\n",
       "      <td>0.945652</td>\n",
       "      <td>0.945652</td>\n",
       "      <td>0.902174</td>\n",
       "      <td>0.925065</td>\n",
       "      <td>0.023456</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.184376</td>\n",
       "      <td>0.008476</td>\n",
       "      <td>0.008612</td>\n",
       "      <td>0.002722</td>\n",
       "      <td>gini</td>\n",
       "      <td>11</td>\n",
       "      <td>50</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 11, 'n_esti...</td>\n",
       "      <td>0.929730</td>\n",
       "      <td>0.902174</td>\n",
       "      <td>0.961957</td>\n",
       "      <td>0.945652</td>\n",
       "      <td>0.891304</td>\n",
       "      <td>0.926163</td>\n",
       "      <td>0.026322</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.285876</td>\n",
       "      <td>0.002441</td>\n",
       "      <td>0.010800</td>\n",
       "      <td>0.001536</td>\n",
       "      <td>gini</td>\n",
       "      <td>11</td>\n",
       "      <td>75</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 11, 'n_esti...</td>\n",
       "      <td>0.935135</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.961957</td>\n",
       "      <td>0.945652</td>\n",
       "      <td>0.891304</td>\n",
       "      <td>0.929418</td>\n",
       "      <td>0.024802</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.368091</td>\n",
       "      <td>0.007583</td>\n",
       "      <td>0.015514</td>\n",
       "      <td>0.001988</td>\n",
       "      <td>gini</td>\n",
       "      <td>11</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 11, 'n_esti...</td>\n",
       "      <td>0.935135</td>\n",
       "      <td>0.907609</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.940217</td>\n",
       "      <td>0.896739</td>\n",
       "      <td>0.927244</td>\n",
       "      <td>0.021927</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.037007</td>\n",
       "      <td>0.002102</td>\n",
       "      <td>0.002392</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>gini</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 12, 'n_esti...</td>\n",
       "      <td>0.935135</td>\n",
       "      <td>0.902174</td>\n",
       "      <td>0.929348</td>\n",
       "      <td>0.929348</td>\n",
       "      <td>0.869565</td>\n",
       "      <td>0.913114</td>\n",
       "      <td>0.024610</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.099360</td>\n",
       "      <td>0.001036</td>\n",
       "      <td>0.005365</td>\n",
       "      <td>0.000788</td>\n",
       "      <td>gini</td>\n",
       "      <td>12</td>\n",
       "      <td>25</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 12, 'n_esti...</td>\n",
       "      <td>0.929730</td>\n",
       "      <td>0.896739</td>\n",
       "      <td>0.934783</td>\n",
       "      <td>0.929348</td>\n",
       "      <td>0.885870</td>\n",
       "      <td>0.915294</td>\n",
       "      <td>0.019979</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.201910</td>\n",
       "      <td>0.018116</td>\n",
       "      <td>0.007630</td>\n",
       "      <td>0.000524</td>\n",
       "      <td>gini</td>\n",
       "      <td>12</td>\n",
       "      <td>50</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 12, 'n_esti...</td>\n",
       "      <td>0.935135</td>\n",
       "      <td>0.896739</td>\n",
       "      <td>0.961957</td>\n",
       "      <td>0.940217</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.929418</td>\n",
       "      <td>0.022557</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.347168</td>\n",
       "      <td>0.014602</td>\n",
       "      <td>0.012125</td>\n",
       "      <td>0.000702</td>\n",
       "      <td>gini</td>\n",
       "      <td>12</td>\n",
       "      <td>75</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 12, 'n_esti...</td>\n",
       "      <td>0.935135</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.967391</td>\n",
       "      <td>0.951087</td>\n",
       "      <td>0.907609</td>\n",
       "      <td>0.934853</td>\n",
       "      <td>0.022540</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.441400</td>\n",
       "      <td>0.015387</td>\n",
       "      <td>0.019623</td>\n",
       "      <td>0.011784</td>\n",
       "      <td>gini</td>\n",
       "      <td>12</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 12, 'n_esti...</td>\n",
       "      <td>0.929730</td>\n",
       "      <td>0.891304</td>\n",
       "      <td>0.961957</td>\n",
       "      <td>0.945652</td>\n",
       "      <td>0.907609</td>\n",
       "      <td>0.927250</td>\n",
       "      <td>0.025406</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.038349</td>\n",
       "      <td>0.000706</td>\n",
       "      <td>0.002662</td>\n",
       "      <td>0.000375</td>\n",
       "      <td>entropy</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 10, 'n_e...</td>\n",
       "      <td>0.951351</td>\n",
       "      <td>0.880435</td>\n",
       "      <td>0.951087</td>\n",
       "      <td>0.907609</td>\n",
       "      <td>0.896739</td>\n",
       "      <td>0.917444</td>\n",
       "      <td>0.028902</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.107910</td>\n",
       "      <td>0.013172</td>\n",
       "      <td>0.005194</td>\n",
       "      <td>0.001497</td>\n",
       "      <td>entropy</td>\n",
       "      <td>10</td>\n",
       "      <td>25</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 10, 'n_e...</td>\n",
       "      <td>0.929730</td>\n",
       "      <td>0.918478</td>\n",
       "      <td>0.951087</td>\n",
       "      <td>0.934783</td>\n",
       "      <td>0.902174</td>\n",
       "      <td>0.927250</td>\n",
       "      <td>0.016351</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.202481</td>\n",
       "      <td>0.008205</td>\n",
       "      <td>0.007392</td>\n",
       "      <td>0.000382</td>\n",
       "      <td>entropy</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 10, 'n_e...</td>\n",
       "      <td>0.940541</td>\n",
       "      <td>0.907609</td>\n",
       "      <td>0.945652</td>\n",
       "      <td>0.934783</td>\n",
       "      <td>0.891304</td>\n",
       "      <td>0.923978</td>\n",
       "      <td>0.020959</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.264763</td>\n",
       "      <td>0.012736</td>\n",
       "      <td>0.010873</td>\n",
       "      <td>0.000803</td>\n",
       "      <td>entropy</td>\n",
       "      <td>10</td>\n",
       "      <td>75</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 10, 'n_e...</td>\n",
       "      <td>0.935135</td>\n",
       "      <td>0.885870</td>\n",
       "      <td>0.951087</td>\n",
       "      <td>0.940217</td>\n",
       "      <td>0.885870</td>\n",
       "      <td>0.919636</td>\n",
       "      <td>0.028048</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.411547</td>\n",
       "      <td>0.027522</td>\n",
       "      <td>0.017950</td>\n",
       "      <td>0.004900</td>\n",
       "      <td>entropy</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 10, 'n_e...</td>\n",
       "      <td>0.935135</td>\n",
       "      <td>0.891304</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.934783</td>\n",
       "      <td>0.902174</td>\n",
       "      <td>0.923984</td>\n",
       "      <td>0.023847</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.052130</td>\n",
       "      <td>0.009879</td>\n",
       "      <td>0.002896</td>\n",
       "      <td>0.000664</td>\n",
       "      <td>entropy</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 11, 'n_e...</td>\n",
       "      <td>0.924324</td>\n",
       "      <td>0.902174</td>\n",
       "      <td>0.945652</td>\n",
       "      <td>0.951087</td>\n",
       "      <td>0.902174</td>\n",
       "      <td>0.925082</td>\n",
       "      <td>0.020734</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.127194</td>\n",
       "      <td>0.029660</td>\n",
       "      <td>0.006333</td>\n",
       "      <td>0.001763</td>\n",
       "      <td>entropy</td>\n",
       "      <td>11</td>\n",
       "      <td>25</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 11, 'n_e...</td>\n",
       "      <td>0.940541</td>\n",
       "      <td>0.902174</td>\n",
       "      <td>0.934783</td>\n",
       "      <td>0.934783</td>\n",
       "      <td>0.885870</td>\n",
       "      <td>0.919630</td>\n",
       "      <td>0.021638</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.251769</td>\n",
       "      <td>0.065815</td>\n",
       "      <td>0.010217</td>\n",
       "      <td>0.003421</td>\n",
       "      <td>entropy</td>\n",
       "      <td>11</td>\n",
       "      <td>50</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 11, 'n_e...</td>\n",
       "      <td>0.945946</td>\n",
       "      <td>0.907609</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.934783</td>\n",
       "      <td>0.902174</td>\n",
       "      <td>0.929407</td>\n",
       "      <td>0.021234</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.336573</td>\n",
       "      <td>0.045790</td>\n",
       "      <td>0.024248</td>\n",
       "      <td>0.013822</td>\n",
       "      <td>entropy</td>\n",
       "      <td>11</td>\n",
       "      <td>75</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 11, 'n_e...</td>\n",
       "      <td>0.935135</td>\n",
       "      <td>0.902174</td>\n",
       "      <td>0.961957</td>\n",
       "      <td>0.945652</td>\n",
       "      <td>0.902174</td>\n",
       "      <td>0.929418</td>\n",
       "      <td>0.023831</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.520975</td>\n",
       "      <td>0.078130</td>\n",
       "      <td>0.022453</td>\n",
       "      <td>0.009669</td>\n",
       "      <td>entropy</td>\n",
       "      <td>11</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 11, 'n_e...</td>\n",
       "      <td>0.951351</td>\n",
       "      <td>0.907609</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.902174</td>\n",
       "      <td>0.934835</td>\n",
       "      <td>0.024582</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.045292</td>\n",
       "      <td>0.003727</td>\n",
       "      <td>0.002971</td>\n",
       "      <td>0.001871</td>\n",
       "      <td>entropy</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 12, 'n_e...</td>\n",
       "      <td>0.929730</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.929348</td>\n",
       "      <td>0.923913</td>\n",
       "      <td>0.902174</td>\n",
       "      <td>0.919642</td>\n",
       "      <td>0.010610</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.126465</td>\n",
       "      <td>0.023760</td>\n",
       "      <td>0.004799</td>\n",
       "      <td>0.002887</td>\n",
       "      <td>entropy</td>\n",
       "      <td>12</td>\n",
       "      <td>25</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 12, 'n_e...</td>\n",
       "      <td>0.940541</td>\n",
       "      <td>0.902174</td>\n",
       "      <td>0.945652</td>\n",
       "      <td>0.934783</td>\n",
       "      <td>0.880435</td>\n",
       "      <td>0.920717</td>\n",
       "      <td>0.025215</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.247960</td>\n",
       "      <td>0.036778</td>\n",
       "      <td>0.006359</td>\n",
       "      <td>0.001737</td>\n",
       "      <td>entropy</td>\n",
       "      <td>12</td>\n",
       "      <td>50</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 12, 'n_e...</td>\n",
       "      <td>0.940541</td>\n",
       "      <td>0.896739</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.934783</td>\n",
       "      <td>0.896739</td>\n",
       "      <td>0.925065</td>\n",
       "      <td>0.024200</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.326078</td>\n",
       "      <td>0.048337</td>\n",
       "      <td>0.012057</td>\n",
       "      <td>0.002404</td>\n",
       "      <td>entropy</td>\n",
       "      <td>12</td>\n",
       "      <td>75</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 12, 'n_e...</td>\n",
       "      <td>0.945946</td>\n",
       "      <td>0.896739</td>\n",
       "      <td>0.951087</td>\n",
       "      <td>0.934783</td>\n",
       "      <td>0.902174</td>\n",
       "      <td>0.926146</td>\n",
       "      <td>0.022486</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.544667</td>\n",
       "      <td>0.079976</td>\n",
       "      <td>0.018408</td>\n",
       "      <td>0.005530</td>\n",
       "      <td>entropy</td>\n",
       "      <td>12</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 12, 'n_e...</td>\n",
       "      <td>0.935135</td>\n",
       "      <td>0.896739</td>\n",
       "      <td>0.961957</td>\n",
       "      <td>0.934783</td>\n",
       "      <td>0.902174</td>\n",
       "      <td>0.926157</td>\n",
       "      <td>0.023988</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.045706</td>\n",
       "      <td>0.011707</td>\n",
       "      <td>0.003909</td>\n",
       "      <td>0.002621</td>\n",
       "      <td>log_loss</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>{'criterion': 'log_loss', 'max_depth': 10, 'n_...</td>\n",
       "      <td>0.913514</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.940217</td>\n",
       "      <td>0.902174</td>\n",
       "      <td>0.869565</td>\n",
       "      <td>0.900094</td>\n",
       "      <td>0.025908</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.157492</td>\n",
       "      <td>0.037115</td>\n",
       "      <td>0.006189</td>\n",
       "      <td>0.001833</td>\n",
       "      <td>log_loss</td>\n",
       "      <td>10</td>\n",
       "      <td>25</td>\n",
       "      <td>{'criterion': 'log_loss', 'max_depth': 10, 'n_...</td>\n",
       "      <td>0.935135</td>\n",
       "      <td>0.902174</td>\n",
       "      <td>0.945652</td>\n",
       "      <td>0.934783</td>\n",
       "      <td>0.896739</td>\n",
       "      <td>0.922897</td>\n",
       "      <td>0.019609</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.232569</td>\n",
       "      <td>0.033694</td>\n",
       "      <td>0.013346</td>\n",
       "      <td>0.006021</td>\n",
       "      <td>log_loss</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>{'criterion': 'log_loss', 'max_depth': 10, 'n_...</td>\n",
       "      <td>0.940541</td>\n",
       "      <td>0.891304</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.934783</td>\n",
       "      <td>0.902174</td>\n",
       "      <td>0.925065</td>\n",
       "      <td>0.024443</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.368884</td>\n",
       "      <td>0.086651</td>\n",
       "      <td>0.014102</td>\n",
       "      <td>0.001939</td>\n",
       "      <td>log_loss</td>\n",
       "      <td>10</td>\n",
       "      <td>75</td>\n",
       "      <td>{'criterion': 'log_loss', 'max_depth': 10, 'n_...</td>\n",
       "      <td>0.929730</td>\n",
       "      <td>0.885870</td>\n",
       "      <td>0.945652</td>\n",
       "      <td>0.940217</td>\n",
       "      <td>0.902174</td>\n",
       "      <td>0.920729</td>\n",
       "      <td>0.022985</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.488145</td>\n",
       "      <td>0.046706</td>\n",
       "      <td>0.016125</td>\n",
       "      <td>0.002226</td>\n",
       "      <td>log_loss</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'log_loss', 'max_depth': 10, 'n_...</td>\n",
       "      <td>0.935135</td>\n",
       "      <td>0.896739</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.940217</td>\n",
       "      <td>0.902174</td>\n",
       "      <td>0.926157</td>\n",
       "      <td>0.022982</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.046160</td>\n",
       "      <td>0.012145</td>\n",
       "      <td>0.004387</td>\n",
       "      <td>0.003344</td>\n",
       "      <td>log_loss</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>{'criterion': 'log_loss', 'max_depth': 11, 'n_...</td>\n",
       "      <td>0.951351</td>\n",
       "      <td>0.891304</td>\n",
       "      <td>0.923913</td>\n",
       "      <td>0.929348</td>\n",
       "      <td>0.885870</td>\n",
       "      <td>0.916357</td>\n",
       "      <td>0.024526</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.122733</td>\n",
       "      <td>0.022762</td>\n",
       "      <td>0.004653</td>\n",
       "      <td>0.000912</td>\n",
       "      <td>log_loss</td>\n",
       "      <td>11</td>\n",
       "      <td>25</td>\n",
       "      <td>{'criterion': 'log_loss', 'max_depth': 11, 'n_...</td>\n",
       "      <td>0.924324</td>\n",
       "      <td>0.902174</td>\n",
       "      <td>0.961957</td>\n",
       "      <td>0.929348</td>\n",
       "      <td>0.891304</td>\n",
       "      <td>0.921821</td>\n",
       "      <td>0.024458</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.226322</td>\n",
       "      <td>0.033389</td>\n",
       "      <td>0.008466</td>\n",
       "      <td>0.002652</td>\n",
       "      <td>log_loss</td>\n",
       "      <td>11</td>\n",
       "      <td>50</td>\n",
       "      <td>{'criterion': 'log_loss', 'max_depth': 11, 'n_...</td>\n",
       "      <td>0.940541</td>\n",
       "      <td>0.907609</td>\n",
       "      <td>0.961957</td>\n",
       "      <td>0.945652</td>\n",
       "      <td>0.902174</td>\n",
       "      <td>0.931586</td>\n",
       "      <td>0.022980</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.349439</td>\n",
       "      <td>0.065761</td>\n",
       "      <td>0.012608</td>\n",
       "      <td>0.001965</td>\n",
       "      <td>log_loss</td>\n",
       "      <td>11</td>\n",
       "      <td>75</td>\n",
       "      <td>{'criterion': 'log_loss', 'max_depth': 11, 'n_...</td>\n",
       "      <td>0.945946</td>\n",
       "      <td>0.891304</td>\n",
       "      <td>0.940217</td>\n",
       "      <td>0.934783</td>\n",
       "      <td>0.885870</td>\n",
       "      <td>0.919624</td>\n",
       "      <td>0.025644</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.450530</td>\n",
       "      <td>0.047410</td>\n",
       "      <td>0.021470</td>\n",
       "      <td>0.006713</td>\n",
       "      <td>log_loss</td>\n",
       "      <td>11</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'log_loss', 'max_depth': 11, 'n_...</td>\n",
       "      <td>0.929730</td>\n",
       "      <td>0.885870</td>\n",
       "      <td>0.961957</td>\n",
       "      <td>0.940217</td>\n",
       "      <td>0.902174</td>\n",
       "      <td>0.923989</td>\n",
       "      <td>0.027081</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.056546</td>\n",
       "      <td>0.011656</td>\n",
       "      <td>0.003310</td>\n",
       "      <td>0.001868</td>\n",
       "      <td>log_loss</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>{'criterion': 'log_loss', 'max_depth': 12, 'n_...</td>\n",
       "      <td>0.908108</td>\n",
       "      <td>0.880435</td>\n",
       "      <td>0.934783</td>\n",
       "      <td>0.918478</td>\n",
       "      <td>0.896739</td>\n",
       "      <td>0.907709</td>\n",
       "      <td>0.018511</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.127001</td>\n",
       "      <td>0.025134</td>\n",
       "      <td>0.003731</td>\n",
       "      <td>0.002430</td>\n",
       "      <td>log_loss</td>\n",
       "      <td>12</td>\n",
       "      <td>25</td>\n",
       "      <td>{'criterion': 'log_loss', 'max_depth': 12, 'n_...</td>\n",
       "      <td>0.935135</td>\n",
       "      <td>0.918478</td>\n",
       "      <td>0.940217</td>\n",
       "      <td>0.929348</td>\n",
       "      <td>0.896739</td>\n",
       "      <td>0.923984</td>\n",
       "      <td>0.015422</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.259198</td>\n",
       "      <td>0.044881</td>\n",
       "      <td>0.007756</td>\n",
       "      <td>0.001290</td>\n",
       "      <td>log_loss</td>\n",
       "      <td>12</td>\n",
       "      <td>50</td>\n",
       "      <td>{'criterion': 'log_loss', 'max_depth': 12, 'n_...</td>\n",
       "      <td>0.945946</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.961957</td>\n",
       "      <td>0.945652</td>\n",
       "      <td>0.907609</td>\n",
       "      <td>0.934841</td>\n",
       "      <td>0.020939</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.305193</td>\n",
       "      <td>0.029288</td>\n",
       "      <td>0.010158</td>\n",
       "      <td>0.000379</td>\n",
       "      <td>log_loss</td>\n",
       "      <td>12</td>\n",
       "      <td>75</td>\n",
       "      <td>{'criterion': 'log_loss', 'max_depth': 12, 'n_...</td>\n",
       "      <td>0.945946</td>\n",
       "      <td>0.918478</td>\n",
       "      <td>0.961957</td>\n",
       "      <td>0.940217</td>\n",
       "      <td>0.918478</td>\n",
       "      <td>0.937015</td>\n",
       "      <td>0.016729</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.380455</td>\n",
       "      <td>0.025344</td>\n",
       "      <td>0.010712</td>\n",
       "      <td>0.002599</td>\n",
       "      <td>log_loss</td>\n",
       "      <td>12</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'log_loss', 'max_depth': 12, 'n_...</td>\n",
       "      <td>0.940541</td>\n",
       "      <td>0.896739</td>\n",
       "      <td>0.961957</td>\n",
       "      <td>0.945652</td>\n",
       "      <td>0.891304</td>\n",
       "      <td>0.927239</td>\n",
       "      <td>0.028081</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0        0.051290      0.005361         0.003976        0.000569   \n",
       "1        0.089697      0.004951         0.003454        0.002394   \n",
       "2        0.188713      0.010927         0.010764        0.002466   \n",
       "3        0.286051      0.019875         0.009791        0.000506   \n",
       "4        0.365269      0.010018         0.014212        0.001676   \n",
       "5        0.033946      0.001539         0.002199        0.000411   \n",
       "6        0.093932      0.007733         0.005180        0.001043   \n",
       "7        0.184376      0.008476         0.008612        0.002722   \n",
       "8        0.285876      0.002441         0.010800        0.001536   \n",
       "9        0.368091      0.007583         0.015514        0.001988   \n",
       "10       0.037007      0.002102         0.002392        0.000488   \n",
       "11       0.099360      0.001036         0.005365        0.000788   \n",
       "12       0.201910      0.018116         0.007630        0.000524   \n",
       "13       0.347168      0.014602         0.012125        0.000702   \n",
       "14       0.441400      0.015387         0.019623        0.011784   \n",
       "15       0.038349      0.000706         0.002662        0.000375   \n",
       "16       0.107910      0.013172         0.005194        0.001497   \n",
       "17       0.202481      0.008205         0.007392        0.000382   \n",
       "18       0.264763      0.012736         0.010873        0.000803   \n",
       "19       0.411547      0.027522         0.017950        0.004900   \n",
       "20       0.052130      0.009879         0.002896        0.000664   \n",
       "21       0.127194      0.029660         0.006333        0.001763   \n",
       "22       0.251769      0.065815         0.010217        0.003421   \n",
       "23       0.336573      0.045790         0.024248        0.013822   \n",
       "24       0.520975      0.078130         0.022453        0.009669   \n",
       "25       0.045292      0.003727         0.002971        0.001871   \n",
       "26       0.126465      0.023760         0.004799        0.002887   \n",
       "27       0.247960      0.036778         0.006359        0.001737   \n",
       "28       0.326078      0.048337         0.012057        0.002404   \n",
       "29       0.544667      0.079976         0.018408        0.005530   \n",
       "30       0.045706      0.011707         0.003909        0.002621   \n",
       "31       0.157492      0.037115         0.006189        0.001833   \n",
       "32       0.232569      0.033694         0.013346        0.006021   \n",
       "33       0.368884      0.086651         0.014102        0.001939   \n",
       "34       0.488145      0.046706         0.016125        0.002226   \n",
       "35       0.046160      0.012145         0.004387        0.003344   \n",
       "36       0.122733      0.022762         0.004653        0.000912   \n",
       "37       0.226322      0.033389         0.008466        0.002652   \n",
       "38       0.349439      0.065761         0.012608        0.001965   \n",
       "39       0.450530      0.047410         0.021470        0.006713   \n",
       "40       0.056546      0.011656         0.003310        0.001868   \n",
       "41       0.127001      0.025134         0.003731        0.002430   \n",
       "42       0.259198      0.044881         0.007756        0.001290   \n",
       "43       0.305193      0.029288         0.010158        0.000379   \n",
       "44       0.380455      0.025344         0.010712        0.002599   \n",
       "\n",
       "   param_criterion param_max_depth param_n_estimators  \\\n",
       "0             gini              10                 10   \n",
       "1             gini              10                 25   \n",
       "2             gini              10                 50   \n",
       "3             gini              10                 75   \n",
       "4             gini              10                100   \n",
       "5             gini              11                 10   \n",
       "6             gini              11                 25   \n",
       "7             gini              11                 50   \n",
       "8             gini              11                 75   \n",
       "9             gini              11                100   \n",
       "10            gini              12                 10   \n",
       "11            gini              12                 25   \n",
       "12            gini              12                 50   \n",
       "13            gini              12                 75   \n",
       "14            gini              12                100   \n",
       "15         entropy              10                 10   \n",
       "16         entropy              10                 25   \n",
       "17         entropy              10                 50   \n",
       "18         entropy              10                 75   \n",
       "19         entropy              10                100   \n",
       "20         entropy              11                 10   \n",
       "21         entropy              11                 25   \n",
       "22         entropy              11                 50   \n",
       "23         entropy              11                 75   \n",
       "24         entropy              11                100   \n",
       "25         entropy              12                 10   \n",
       "26         entropy              12                 25   \n",
       "27         entropy              12                 50   \n",
       "28         entropy              12                 75   \n",
       "29         entropy              12                100   \n",
       "30        log_loss              10                 10   \n",
       "31        log_loss              10                 25   \n",
       "32        log_loss              10                 50   \n",
       "33        log_loss              10                 75   \n",
       "34        log_loss              10                100   \n",
       "35        log_loss              11                 10   \n",
       "36        log_loss              11                 25   \n",
       "37        log_loss              11                 50   \n",
       "38        log_loss              11                 75   \n",
       "39        log_loss              11                100   \n",
       "40        log_loss              12                 10   \n",
       "41        log_loss              12                 25   \n",
       "42        log_loss              12                 50   \n",
       "43        log_loss              12                 75   \n",
       "44        log_loss              12                100   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "0   {'criterion': 'gini', 'max_depth': 10, 'n_esti...           0.940541   \n",
       "1   {'criterion': 'gini', 'max_depth': 10, 'n_esti...           0.956757   \n",
       "2   {'criterion': 'gini', 'max_depth': 10, 'n_esti...           0.945946   \n",
       "3   {'criterion': 'gini', 'max_depth': 10, 'n_esti...           0.940541   \n",
       "4   {'criterion': 'gini', 'max_depth': 10, 'n_esti...           0.935135   \n",
       "5   {'criterion': 'gini', 'max_depth': 11, 'n_esti...           0.929730   \n",
       "6   {'criterion': 'gini', 'max_depth': 11, 'n_esti...           0.940541   \n",
       "7   {'criterion': 'gini', 'max_depth': 11, 'n_esti...           0.929730   \n",
       "8   {'criterion': 'gini', 'max_depth': 11, 'n_esti...           0.935135   \n",
       "9   {'criterion': 'gini', 'max_depth': 11, 'n_esti...           0.935135   \n",
       "10  {'criterion': 'gini', 'max_depth': 12, 'n_esti...           0.935135   \n",
       "11  {'criterion': 'gini', 'max_depth': 12, 'n_esti...           0.929730   \n",
       "12  {'criterion': 'gini', 'max_depth': 12, 'n_esti...           0.935135   \n",
       "13  {'criterion': 'gini', 'max_depth': 12, 'n_esti...           0.935135   \n",
       "14  {'criterion': 'gini', 'max_depth': 12, 'n_esti...           0.929730   \n",
       "15  {'criterion': 'entropy', 'max_depth': 10, 'n_e...           0.951351   \n",
       "16  {'criterion': 'entropy', 'max_depth': 10, 'n_e...           0.929730   \n",
       "17  {'criterion': 'entropy', 'max_depth': 10, 'n_e...           0.940541   \n",
       "18  {'criterion': 'entropy', 'max_depth': 10, 'n_e...           0.935135   \n",
       "19  {'criterion': 'entropy', 'max_depth': 10, 'n_e...           0.935135   \n",
       "20  {'criterion': 'entropy', 'max_depth': 11, 'n_e...           0.924324   \n",
       "21  {'criterion': 'entropy', 'max_depth': 11, 'n_e...           0.940541   \n",
       "22  {'criterion': 'entropy', 'max_depth': 11, 'n_e...           0.945946   \n",
       "23  {'criterion': 'entropy', 'max_depth': 11, 'n_e...           0.935135   \n",
       "24  {'criterion': 'entropy', 'max_depth': 11, 'n_e...           0.951351   \n",
       "25  {'criterion': 'entropy', 'max_depth': 12, 'n_e...           0.929730   \n",
       "26  {'criterion': 'entropy', 'max_depth': 12, 'n_e...           0.940541   \n",
       "27  {'criterion': 'entropy', 'max_depth': 12, 'n_e...           0.940541   \n",
       "28  {'criterion': 'entropy', 'max_depth': 12, 'n_e...           0.945946   \n",
       "29  {'criterion': 'entropy', 'max_depth': 12, 'n_e...           0.935135   \n",
       "30  {'criterion': 'log_loss', 'max_depth': 10, 'n_...           0.913514   \n",
       "31  {'criterion': 'log_loss', 'max_depth': 10, 'n_...           0.935135   \n",
       "32  {'criterion': 'log_loss', 'max_depth': 10, 'n_...           0.940541   \n",
       "33  {'criterion': 'log_loss', 'max_depth': 10, 'n_...           0.929730   \n",
       "34  {'criterion': 'log_loss', 'max_depth': 10, 'n_...           0.935135   \n",
       "35  {'criterion': 'log_loss', 'max_depth': 11, 'n_...           0.951351   \n",
       "36  {'criterion': 'log_loss', 'max_depth': 11, 'n_...           0.924324   \n",
       "37  {'criterion': 'log_loss', 'max_depth': 11, 'n_...           0.940541   \n",
       "38  {'criterion': 'log_loss', 'max_depth': 11, 'n_...           0.945946   \n",
       "39  {'criterion': 'log_loss', 'max_depth': 11, 'n_...           0.929730   \n",
       "40  {'criterion': 'log_loss', 'max_depth': 12, 'n_...           0.908108   \n",
       "41  {'criterion': 'log_loss', 'max_depth': 12, 'n_...           0.935135   \n",
       "42  {'criterion': 'log_loss', 'max_depth': 12, 'n_...           0.945946   \n",
       "43  {'criterion': 'log_loss', 'max_depth': 12, 'n_...           0.945946   \n",
       "44  {'criterion': 'log_loss', 'max_depth': 12, 'n_...           0.940541   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0            0.891304           0.923913           0.902174   \n",
       "1            0.907609           0.945652           0.940217   \n",
       "2            0.880435           0.961957           0.929348   \n",
       "3            0.907609           0.961957           0.934783   \n",
       "4            0.891304           0.956522           0.934783   \n",
       "5            0.880435           0.923913           0.929348   \n",
       "6            0.891304           0.945652           0.945652   \n",
       "7            0.902174           0.961957           0.945652   \n",
       "8            0.913043           0.961957           0.945652   \n",
       "9            0.907609           0.956522           0.940217   \n",
       "10           0.902174           0.929348           0.929348   \n",
       "11           0.896739           0.934783           0.929348   \n",
       "12           0.896739           0.961957           0.940217   \n",
       "13           0.913043           0.967391           0.951087   \n",
       "14           0.891304           0.961957           0.945652   \n",
       "15           0.880435           0.951087           0.907609   \n",
       "16           0.918478           0.951087           0.934783   \n",
       "17           0.907609           0.945652           0.934783   \n",
       "18           0.885870           0.951087           0.940217   \n",
       "19           0.891304           0.956522           0.934783   \n",
       "20           0.902174           0.945652           0.951087   \n",
       "21           0.902174           0.934783           0.934783   \n",
       "22           0.907609           0.956522           0.934783   \n",
       "23           0.902174           0.961957           0.945652   \n",
       "24           0.907609           0.956522           0.956522   \n",
       "25           0.913043           0.929348           0.923913   \n",
       "26           0.902174           0.945652           0.934783   \n",
       "27           0.896739           0.956522           0.934783   \n",
       "28           0.896739           0.951087           0.934783   \n",
       "29           0.896739           0.961957           0.934783   \n",
       "30           0.875000           0.940217           0.902174   \n",
       "31           0.902174           0.945652           0.934783   \n",
       "32           0.891304           0.956522           0.934783   \n",
       "33           0.885870           0.945652           0.940217   \n",
       "34           0.896739           0.956522           0.940217   \n",
       "35           0.891304           0.923913           0.929348   \n",
       "36           0.902174           0.961957           0.929348   \n",
       "37           0.907609           0.961957           0.945652   \n",
       "38           0.891304           0.940217           0.934783   \n",
       "39           0.885870           0.961957           0.940217   \n",
       "40           0.880435           0.934783           0.918478   \n",
       "41           0.918478           0.940217           0.929348   \n",
       "42           0.913043           0.961957           0.945652   \n",
       "43           0.918478           0.961957           0.940217   \n",
       "44           0.896739           0.961957           0.945652   \n",
       "\n",
       "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0            0.875000         0.906586        0.023254               44  \n",
       "1            0.896739         0.929395        0.023113               10  \n",
       "2            0.902174         0.923972        0.029412               28  \n",
       "3            0.896739         0.928325        0.023447               11  \n",
       "4            0.885870         0.920723        0.027449               32  \n",
       "5            0.896739         0.912033        0.019932               42  \n",
       "6            0.902174         0.925065        0.023456               21  \n",
       "7            0.891304         0.926163        0.026322               16  \n",
       "8            0.891304         0.929418        0.024802                7  \n",
       "9            0.896739         0.927244        0.021927               14  \n",
       "10           0.869565         0.913114        0.024610               41  \n",
       "11           0.885870         0.915294        0.019979               40  \n",
       "12           0.913043         0.929418        0.022557                7  \n",
       "13           0.907609         0.934853        0.022540                2  \n",
       "14           0.907609         0.927250        0.025406               12  \n",
       "15           0.896739         0.917444        0.028902               38  \n",
       "16           0.902174         0.927250        0.016351               12  \n",
       "17           0.891304         0.923978        0.020959               27  \n",
       "18           0.885870         0.919636        0.028048               35  \n",
       "19           0.902174         0.923984        0.023847               25  \n",
       "20           0.902174         0.925082        0.020734               20  \n",
       "21           0.885870         0.919630        0.021638               36  \n",
       "22           0.902174         0.929407        0.021234                9  \n",
       "23           0.902174         0.929418        0.023831                6  \n",
       "24           0.902174         0.934835        0.024582                4  \n",
       "25           0.902174         0.919642        0.010610               34  \n",
       "26           0.880435         0.920717        0.025215               33  \n",
       "27           0.896739         0.925065        0.024200               21  \n",
       "28           0.902174         0.926146        0.022486               19  \n",
       "29           0.902174         0.926157        0.023988               17  \n",
       "30           0.869565         0.900094        0.025908               45  \n",
       "31           0.896739         0.922897        0.019609               29  \n",
       "32           0.902174         0.925065        0.024443               21  \n",
       "33           0.902174         0.920729        0.022985               31  \n",
       "34           0.902174         0.926157        0.022982               17  \n",
       "35           0.885870         0.916357        0.024526               39  \n",
       "36           0.891304         0.921821        0.024458               30  \n",
       "37           0.902174         0.931586        0.022980                5  \n",
       "38           0.885870         0.919624        0.025644               37  \n",
       "39           0.902174         0.923989        0.027081               24  \n",
       "40           0.896739         0.907709        0.018511               43  \n",
       "41           0.896739         0.923984        0.015422               25  \n",
       "42           0.907609         0.934841        0.020939                3  \n",
       "43           0.918478         0.937015        0.016729                1  \n",
       "44           0.891304         0.927239        0.028081               15  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = X_all\n",
    "y = y_all\n",
    "\n",
    "num = []\n",
    "\n",
    "for i in range(5):\n",
    "    params, clf = classifier_select(i + 1)\n",
    "    num.append(clf)\n",
    "\n",
    "def ensemble_select(fselect, fnum):\n",
    "    \n",
    "    if fselect == 1:\n",
    "        adc = AdaBoostClassifier()\n",
    "        adc_params = [{'estimator': fnum, \n",
    "                       'n_estimators': [10, 25, 50, 75, 100], \n",
    "                       'learning_rate': [0.7, 0.8, 1]}] \n",
    "        \n",
    "        return adc, adc_params\n",
    "\n",
    "    elif fselect == 2:\n",
    "        rfc = RandomForestClassifier()\n",
    "        rfc_params = [{'n_estimators': [10, 25, 50, 75, 100], \n",
    "                       \"criterion\": [\"gini\", 'entropy', \"log_loss\"], \n",
    "                       \"max_depth\": [10, 11, 12]}]\n",
    "        \n",
    "        return rfc, rfc_params\n",
    "    \n",
    "    else:\n",
    "        bg = BaggingClassifier()\n",
    "        bg_params = [{'estimator': fnum, \n",
    "                      'n_estimators': [10, 25, 50, 75, 100], \n",
    "                      'max_samples': [0.7, 0.8, 1]}]\n",
    "        \n",
    "        return bg, bg_params\n",
    "        \n",
    "\n",
    "clf, params = ensemble_select(2, num)\n",
    "\n",
    "X,X_val,y,y_val=train_test_split(X,y,test_size=0.2,random_state=42, stratify=y)\n",
    "\n",
    "gs=GridSearchCV(clf, params, scoring='accuracy', cv=5, n_jobs=-1)\n",
    "\n",
    "gs.fit(X_val, y_val)\n",
    "\n",
    "df=gs.cv_results_\n",
    "df = pd.DataFrame(gs.cv_results_)\n",
    "print(\"Melhores parâmetros encontrados: \", gs.best_params_)\n",
    "\n",
    "clf=gs.best_estimator_\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "63e28d18",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia média: 0.563\n",
      "Desvio padrão: 0.007\n",
      "Precision: 0.562\n",
      "Recall: 0.562\n",
      "f1: 0.562\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7f8b7f8c1e40>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result=model_selection.cross_val_score(clf, X, y, cv=5)\n",
    "print(\"Acurácia média: %.3f\" % result.mean())\n",
    "print(\"Desvio padrão: %.3f\" % result.std())\n",
    "\n",
    "# Calculando a predição para cada exemplo de teste\n",
    "y_pred=model_selection.cross_val_predict(clf, X, y, cv=5)\n",
    "\n",
    "# Calcular precisão\n",
    "precision=precision_score(y, y_pred, average='macro')\n",
    "\n",
    "# Calcular revocação\n",
    "recall=recall_score(y, y_pred, average='macro')\n",
    "\n",
    "# Calcular revocação\n",
    "f1=f1_score(y, y_pred, average='macro')\n",
    "\n",
    "print(\"Precision: %.3f\" % precision)\n",
    "print(\"Recall: %.3f\" % recall)\n",
    "print(\"f1: %.3f\" % f1)\n",
    "\n",
    "cm = confusion_matrix(y, y_pred, labels=clf.classes_)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['não_spam', 'spam'])\n",
    "disp.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53aaecf9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
