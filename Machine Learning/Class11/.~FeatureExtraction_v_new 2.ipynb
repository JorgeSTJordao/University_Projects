{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "x-bfht2Sp04O"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.colab'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolab\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m drive\n\u001b[1;32m      2\u001b[0m drive\u001b[38;5;241m.\u001b[39mmount(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/content/drive\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "DsoZD004OfRW"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-18 20:16:06.955155: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-10-18 20:16:07.210944: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-10-18 20:16:07.210992: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-10-18 20:16:07.212680: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-10-18 20:16:07.336901: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-10-18 20:16:07.338386: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-10-18 20:16:08.474225: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/xception/xception_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "83683744/83683744 [==============================] - 30s 0us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-18 20:17:06.610866: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 1228308480 exceeds 10% of free system memory.\n",
      "2023-10-18 20:17:09.984898: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 194658304 exceeds 10% of free system memory.\n",
      "2023-10-18 20:17:10.032574: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 194658304 exceeds 10% of free system memory.\n",
      "2023-10-18 20:17:10.073310: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 194658304 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1/64 [..............................] - ETA: 6:11"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-18 20:17:14.427743: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 194658304 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 123s 2s/step\n"
     ]
    }
   ],
   "source": [
    "# Feature Extraction (Deep Features)\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import math\n",
    "from skimage import feature\n",
    "from skimage.feature import hog\n",
    "from imutils import paths\n",
    "#from google.colab.patches import cv2_imshow\n",
    "import os\n",
    "\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.applications.xception import Xception\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input\n",
    "\n",
    "# Load Inception_v3 pretrained on ImageNet dataset\n",
    "W=224\n",
    "H=224\n",
    "#model = InceptionV3(include_top=False, weights='imagenet', pooling='avg', input_tensor=Input(shape=(W,H,3)))\n",
    "#model = ResNet50(include_top=False, weights='imagenet', pooling='avg', input_tensor=Input(shape=(W,H,3)))\n",
    "model = Xception(include_top=False, weights='imagenet', pooling='avg')\n",
    "\n",
    "# List of paths \n",
    "import os\n",
    "file_list=[]\n",
    "file_list.append(os.listdir(r\"/home/jorge/OneDrive/GitHub/University_Projects/Machine Learning/Class11/fake\"))\n",
    "file_list.append(os.listdir(r\"/home/jorge/OneDrive/GitHub/University_Projects/Machine Learning/Class11/real\"))\n",
    "\n",
    "# general path\n",
    "path='/home/jorge/OneDrive/GitHub/University_Projects/Machine Learning/Class11/'\n",
    "\n",
    "# list of classes\n",
    "class_names=['fake', 'real']\n",
    "\n",
    "X_deep = []\n",
    "y = []\n",
    "\n",
    "# Gera lista com as imagens\n",
    "for classes_files, classe in zip (file_list, range(2)):\n",
    "    for i in range(len(classes_files)):\n",
    "      name= str(path) + str(class_names[classe]) + str('/') + str(classes_files[i]) \n",
    "#      print(name)\n",
    "      y.append(classe)\n",
    "      \n",
    "# Carrega a imagem, pré-processa e inclui em uma lista \n",
    "      imagem = cv2.imread(name)\n",
    "      img = cv2.resize(imagem,(W,H))\n",
    "      xd = image.img_to_array(img)\n",
    "      xd = np.expand_dims(xd, axis=0)\n",
    "      xd = preprocess_input(xd)\n",
    "      X_deep.append(xd)\n",
    "\n",
    "# Extrai características usando o modelo profundo pré-treinado (deep learning)\n",
    "X_deep = np.asarray(X_deep)\n",
    "X_deep = X_deep.reshape(X_deep.shape[0], W, H, 3)\n",
    "X =  model.predict(X_deep)      \n",
    "\n",
    "# Salva as características extraídas em um csv (um vetor de valores para cada imagem)\n",
    "df = pd.DataFrame(X)\n",
    "df.to_csv('X_im.csv', header=False, index=False)\n",
    "\n",
    "# Salva y que contém a classe de cada imagem\n",
    "df_class = pd.DataFrame(y)\n",
    "df_class.to_csv('y_im.csv', header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S5rl3X6iTAb0"
   },
   "outputs": [],
   "source": [
    "# Exemplo de como carregar os arquivos gerados\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Labels\n",
    "y = pd.read_csv('y_im.csv', header=None)\n",
    "y=y.to_numpy()\n",
    "y=np.ravel(y)\n",
    "print(y.shape)\n",
    "\n",
    "# deep features\n",
    "X = pd.read_csv('X_im.csv', header=None)\n",
    "X=X.to_numpy()\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RoYOqTQqPiH9"
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "\n",
    "# Definição dos parâmetros a serem avaliados\n",
    "parameters=[{'hidden_layer_sizes':[1000, (1000,500)], \n",
    "             'activation':['relu', 'logistic'],}]\n",
    "\n",
    "# Separar uma parte dos dados para validação\n",
    "#X, X_val, y, y_val=train_test_split(X, y, train_size=0.8, random_state=42, stratify=y)\n",
    "\n",
    "# definição da técnica a ser utilizada\n",
    "mlp=MLPClassifier(random_state=46, max_iter=500, hidden_layer_sizes=(1000, 500))\n",
    "\n",
    "#gs=GridSearchCV(mlp, parameters, cv=5)\n",
    "#gs.fit(X_val, y_val)\n",
    "#mlp=gs.best_estimator_\n",
    "#print(\"Melhores parâmetros:\", gs.best_params_)\n",
    "\n",
    "#from tabulate import tabulate\n",
    "#df=gs.cv_results_\n",
    "#print(tabulate(df, headers='keys', tablefmt='psql'))\n",
    "\n",
    "result=model_selection.cross_val_score(mlp, X, y, cv=5)\n",
    "print(\"Accuracy: %.5f\" % result.mean())\n",
    "print(\"std: %.5f\" % result.std())\n",
    "y_pred=model_selection.cross_val_predict(mlp, X, y, cv=5)\n",
    "ma=confusion_matrix(y, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(ma)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
