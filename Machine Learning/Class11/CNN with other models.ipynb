{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "300bfcdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Classifiers and Ensembles\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "# Metrics\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0352c21e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# deep features\n",
    "X = pd.read_csv('X_im.csv', header=None)\n",
    "X=X.to_numpy()\n",
    "\n",
    "# Labels\n",
    "y = pd.read_csv('y_im.csv', header=None)\n",
    "y=y.to_numpy()\n",
    "y=np.ravel(y)\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aabc060",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifier_select(fselect):\n",
    "    \n",
    "    # KNeighborsClassifier\n",
    "    if fselect == 1:\n",
    "\n",
    "        knn_params=[{'n_neighbors':[1,3,5,7,9,11], 'weights': ['uniform', 'distance'], 'p':[1,2]}]\n",
    "        knn = KNeighborsClassifier()\n",
    "        \n",
    "        return knn_params, knn\n",
    "        \n",
    "    # Naive Bayes\n",
    "    elif fselect == 2:\n",
    "        \n",
    "        nb_params=[{'var_smoothing':[1e-09,1e-03, 1e-06]}]\n",
    "        nb = GaussianNB()\n",
    "    \n",
    "        return nb_params, nb\n",
    "        \n",
    "    # Decision Tree\n",
    "    elif fselect == 3:\n",
    "        \n",
    "        dc_params=[{'criterion':['gini', 'entropy', 'log_loss'],\n",
    "            'max_depth': [None, 5, 10],\n",
    "            'min_samples_split':[2, 5],\n",
    "            'splitter':['random', 'best']}] \n",
    "        dt = DecisionTreeClassifier()\n",
    "        \n",
    "        return dc_params, dt\n",
    "        \n",
    "    # Multilayer perceptron\n",
    "    elif fselect == 4:\n",
    "        \n",
    "        mlp_params=[{'hidden_layer_sizes':[16, (16, 8), (16, 8, 4)],\n",
    "                   'learning_rate': ['constant', 'invscaling'],\n",
    "                    'learning_rate_init':[0.01, 0.001, 0.0001],\n",
    "                    'activation':['relu', 'logistic', 'tanh'],\n",
    "                   'random_state':[10, 46, 37]}] \n",
    "        mlp = MLPClassifier()\n",
    "        \n",
    "        return mlp_params, mlp \n",
    "        \n",
    "    # Support Vector Machine\n",
    "    else:\n",
    "        svm_params=[{'kernel':[\"linear\", \"poly\"]}]\n",
    "        svm = SVC()\n",
    "        \n",
    "        return svm_params, svm\n",
    "\n",
    "params, clf = classifier_select(4)\n",
    "    \n",
    "X,X_val,y,y_val = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "\n",
    "gs=GridSearchCV(clf, params, scoring='accuracy', cv=5, n_jobs=-1)\n",
    "\n",
    "gs.fit(X_val, y_val)\n",
    "\n",
    "df=gs.cv_results_\n",
    "df = pd.DataFrame(gs.cv_results_)\n",
    "print(\"Melhores parâmetros encontrados: \", gs.best_params_)\n",
    "\n",
    "clf = gs.best_estimator_\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f354830d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X_all\n",
    "y = y_all\n",
    "\n",
    "num = []\n",
    "\n",
    "for i in range(5):\n",
    "    params, clf = classifier_select(i + 1)\n",
    "    num.append(clf)\n",
    "\n",
    "def ensemble_select(fselect, fnum):\n",
    "    \n",
    "    if fselect == 1:\n",
    "        adc = AdaBoostClassifier()\n",
    "        adc_params = [{'estimator': fnum, \n",
    "                       'n_estimators': [10, 25, 50, 75, 100], \n",
    "                       'learning_rate': [0.7, 0.8, 1]}] \n",
    "        \n",
    "        return adc, adc_params\n",
    "\n",
    "    elif fselect == 2:\n",
    "        rfc = RandomForestClassifier()\n",
    "        rfc_params = [{'n_estimators': [10, 25, 50, 75, 100], \n",
    "                       \"criterion\": [\"gini\", 'entropy', \"log_loss\"], \n",
    "                       \"max_depth\": [10, 11, 12]}]\n",
    "        \n",
    "        return rfc, rfc_params\n",
    "    \n",
    "    else:\n",
    "        bg = BaggingClassifier()\n",
    "        bg_params = [{'estimator': fnum, \n",
    "                      'n_estimators': [10, 25, 50, 75, 100], \n",
    "                      'max_samples': [0.7, 0.8, 1]}]\n",
    "        \n",
    "        return bg, bg_params\n",
    "        \n",
    "\n",
    "clf, params = ensemble_select(2, num)\n",
    "\n",
    "X,X_val,y,y_val=train_test_split(X,y,test_size=0.2,random_state=42, stratify=y)\n",
    "\n",
    "gs=GridSearchCV(clf, params, scoring='accuracy', cv=5, n_jobs=-1)\n",
    "\n",
    "gs.fit(X_val, y_val)\n",
    "\n",
    "df=gs.cv_results_\n",
    "df = pd.DataFrame(gs.cv_results_)\n",
    "print(\"Melhores parâmetros encontrados: \", gs.best_params_)\n",
    "\n",
    "clf=gs.best_estimator_\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e28d18",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "result=model_selection.cross_val_score(clf, X, y, cv=5)\n",
    "print(\"Acurácia média: %.3f\" % result.mean())\n",
    "print(\"Desvio padrão: %.3f\" % result.std())\n",
    "\n",
    "# Calculando a predição para cada exemplo de teste\n",
    "y_pred=model_selection.cross_val_predict(clf, X, y, cv=5)\n",
    "\n",
    "# Calcular precisão\n",
    "precision=precision_score(y, y_pred, average='macro')\n",
    "\n",
    "# Calcular revocação\n",
    "recall=recall_score(y, y_pred, average='macro')\n",
    "\n",
    "# Calcular revocação\n",
    "f1=f1_score(y, y_pred, average='macro')\n",
    "\n",
    "print(\"Precision: %.3f\" % precision)\n",
    "print(\"Recall: %.3f\" % recall)\n",
    "print(\"f1: %.3f\" % f1)\n",
    "\n",
    "cm = confusion_matrix(y, y_pred, labels=clf.classes_)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
